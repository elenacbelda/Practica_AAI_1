{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip3.12 install missingno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.tree import export_text\n",
    "import seaborn as sns\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis preliminar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data_100 = pd.read_csv('train_data_100_lines.csv', encoding='ISO-8859-1')\n",
    "# df_label = pd.read_csv('train_labels_50_lines.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data_100.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Revisar si las transacciones de un mismo cliente están consecutivas\n",
    "# df_data_100['is_consecutive'] = df_data_100['ID'] == df_data_100['ID'].shift()\n",
    "\n",
    "# # Verificar si hay filas donde el ID del cliente no es consecutivo\n",
    "# non_consecutive = df_data_100[df_data_100['is_consecutive'] == False]\n",
    "\n",
    "# if non_consecutive.empty:\n",
    "#     print(\"Todas las transacciones de los clientes están colocadas consecutivamente.\")\n",
    "# else:\n",
    "#     print(f\"Hay {len(non_consecutive)} transacciones que no están consecutivas.\")\n",
    "#     print(non_consecutive[['ID']].drop_duplicates())  # Muestra los IDs no consecutivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv('train_data.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División en csv's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Definir el tamaño objetivo de 500,000 filas por CSV\n",
    "# chunk_size = 500000\n",
    "\n",
    "# # Inicializar variables\n",
    "# current_chunk = []\n",
    "# current_chunk_size = 0\n",
    "# file_index = 1\n",
    "# last_customer_id = None\n",
    "\n",
    "# # Función para guardar el chunk actual en un CSV\n",
    "# def save_chunk(chunk, file_index):\n",
    "#     df_chunk = pd.DataFrame(chunk)\n",
    "#     df_chunk.to_csv(f'train_data_part_{file_index}.csv', index=False)\n",
    "#     print(f'Archivo train_data_part_{file_index}.csv guardado con {len(df_chunk)} filas.')\n",
    "\n",
    "# # Iterar sobre el DataFrame\n",
    "# for i, row in df_data.iterrows():\n",
    "#     customer_id = row['ID']\n",
    "\n",
    "#     # Si hemos alcanzado el tamaño máximo del chunk y el nuevo customer_id es diferente al último en el chunk\n",
    "#     if current_chunk_size >= chunk_size and customer_id != last_customer_id:\n",
    "#         save_chunk(current_chunk, file_index)  # Guardar el CSV actual\n",
    "#         file_index += 1\n",
    "#         current_chunk = []  # Reiniciar el chunk\n",
    "#         current_chunk_size = 0\n",
    "\n",
    "#     # Añadir la fila actual al chunk\n",
    "#     current_chunk.append(row)\n",
    "#     current_chunk_size += 1\n",
    "#     last_customer_id = customer_id\n",
    "\n",
    "# # Guardar el último chunk si no está vacío\n",
    "# if current_chunk:\n",
    "#     save_chunk(current_chunk, file_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data_part_1 = pd.read_csv('train_data_part_1.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage = df_data_part_1.isnull().mean() * 100\n",
    "# columns_with_nulls = percentage[percentage > 0]\n",
    "# print(columns_with_nulls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargado de csv's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo ../data/train_data_part_1.csv cargado en df_data_part_1\n",
      "Archivo ../data/train_data_part_2.csv cargado en df_data_part_2\n",
      "Archivo ../data/train_data_part_3.csv cargado en df_data_part_3\n",
      "Archivo ../data/train_data_part_4.csv cargado en df_data_part_4\n",
      "Archivo ../data/train_data_part_5.csv cargado en df_data_part_5\n",
      "Archivo ../data/train_data_part_6.csv cargado en df_data_part_6\n",
      "Archivo ../data/train_data_part_7.csv cargado en df_data_part_7\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    file_name = f'../data/train_data_part_{i}.csv'\n",
    "    globals()[f'df_data_part_{i}'] = pd.read_csv(file_name, encoding='ISO-8859-1')\n",
    "    print(f'Archivo {file_name} cargado en df_data_part_{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar columnas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_percentage(df, percentage):\n",
    "    null_ratio = {}\n",
    "    for col in df.columns:\n",
    "        ratio = df[col].isna().sum() / len(df) * 100\n",
    "        if ratio > percentage:\n",
    "            null_ratio[col] = ratio\n",
    "           \n",
    "    return null_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo solo con las columnas con menos de 80% de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas con más del 50% de valores nulos en todos los CSVs: ['Infraction_WLMI', 'Infraction_SBF', 'Infraction_ZTLC', 'Base_64022', 'Infraction_IRKE', 'Infraction_CLLY', 'Risk_5797', 'Infraction_HPS', 'Infraction_QGC', 'Infraction_HPLO', 'Infraction_ADWZ', 'Risk_4561', 'Infraction_MAN', 'Infraction_GWL', 'Base_8379', 'Infraction_MZI', 'Expenditure_KMW', 'Infraction_FUSM', 'Infraction_SVKR', 'Infraction_APIU', 'Infraction_ZVHJ', 'Infraction_NCB', 'Infraction_WWLN', 'Infraction_WEG', 'Infraction_EBA', 'Base_3958', 'Infraction_JVWF', 'Infraction_GEL', 'Base_8318', 'Infraction_ANHZ']\n"
     ]
    }
   ],
   "source": [
    "columns_with_high_nulls = []\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    null_columns = set(null_percentage(data_frame, 50).keys())\n",
    "    \n",
    "    # Si es el primer DataFrame, inicializar el conjunto con sus columnas\n",
    "    if i == 1:\n",
    "        columns_with_high_nulls = null_columns\n",
    "    else:\n",
    "        # Mantener solo las columnas que están en todos los DataFrames\n",
    "        columns_with_high_nulls = columns_with_high_nulls.intersection(null_columns)\n",
    "\n",
    "columns_with_high_nulls = list(columns_with_high_nulls)\n",
    "\n",
    "print(f\"Columnas con más del 50% de valores nulos en todos los CSVs: {columns_with_high_nulls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las columnas con más de 80% de valores nulos en todos los csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    data_frame.drop(columns=columns_with_high_nulls, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar si hay filas que tengan todas las columnas a null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay filas completamente nulas en df_data_part_1.\n",
      "No hay filas completamente nulas en df_data_part_2.\n",
      "No hay filas completamente nulas en df_data_part_3.\n",
      "No hay filas completamente nulas en df_data_part_4.\n",
      "No hay filas completamente nulas en df_data_part_5.\n",
      "No hay filas completamente nulas en df_data_part_6.\n",
      "No hay filas completamente nulas en df_data_part_7.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay filas completamente nulas\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    null_rows = data_frame[data_frame.isnull().all(axis=1)]\n",
    "    if not null_rows.empty:\n",
    "        print(f'Filas completamente nulas en df_data_part_{i}:')\n",
    "        print(null_rows)\n",
    "    else:\n",
    "        print(f'No hay filas completamente nulas en df_data_part_{i}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "na_df = df_data_part_1\n",
    "msno.matrix(na_df, figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay filas duplicadas en df_data_part_1.\n",
      "No hay filas duplicadas en df_data_part_2.\n",
      "No hay filas duplicadas en df_data_part_3.\n",
      "No hay filas duplicadas en df_data_part_4.\n",
      "No hay filas duplicadas en df_data_part_5.\n",
      "No hay filas duplicadas en df_data_part_6.\n",
      "No hay filas duplicadas en df_data_part_7.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay filas duplicadas en cada DataFrame\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    duplicate_rows = data_frame[data_frame.duplicated()]\n",
    "    if not duplicate_rows.empty:\n",
    "        print(f'Filas duplicadas en df_data_part_{i}:')\n",
    "        print(duplicate_rows)\n",
    "    else:\n",
    "        print(f'No hay filas duplicadas en df_data_part_{i}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprobar varianza 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay columnas con baja varianza en df_data_part_1.\n",
      "No hay columnas con baja varianza en df_data_part_2.\n",
      "No hay columnas con baja varianza en df_data_part_3.\n",
      "No hay columnas con baja varianza en df_data_part_4.\n",
      "No hay columnas con baja varianza en df_data_part_5.\n",
      "No hay columnas con baja varianza en df_data_part_6.\n",
      "No hay columnas con baja varianza en df_data_part_7.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay columnas con baja varianza\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    low_variance_cols = []\n",
    "    for col in data_frame.columns:\n",
    "        if data_frame[col].nunique() == 1:\n",
    "            low_variance_cols.append(col)\n",
    "    if low_variance_cols:\n",
    "        print(f'Columnas con baja varianza en df_data_part_{i}: {low_variance_cols}')\n",
    "    else:\n",
    "        print(f'No hay columnas con baja varianza en df_data_part_{i}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de tipo de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object: ['ID', 'Expenditure_AHF', 'Infraction_YFSG', 'Infraction_DQLY', 'Infraction_CLH', 'Base_67254', 'Infraction_TEN']\n",
      "float64: ['Payment_6804', 'Infraction_CGP', 'Base_7744', 'Base_80863', 'Risk_1930', 'Expenditure_JIG', 'Infraction_SNZ', 'Base_02683', 'Infraction_ZWWJ', 'Infraction_QJJF', 'Base_76065', 'Infraction_EJZ', 'Base_6872', 'Risk_0322', 'Infraction_FMXQ', 'Infraction_GGO', 'Infraction_TLPJ', 'Base_1165', 'Base_39598', 'Base_6187', 'Infraction_ZTNC', 'Base_85131', 'Risk_9995', 'Infraction_AYWV', 'Payment_22507', 'Base_9516', 'Expenditure_YTR', 'Base_36384', 'Expenditure_FIP', 'Infraction_PAS', 'Risk_0003', 'Expenditure_HMO', 'Base_24406', 'Expenditure_LMSR', 'Infraction_BSU', 'Base_14808', 'Risk_8065', 'Infraction_ZYW', 'Base_1039', 'Infraction_HSSU', 'Infraction_EHZP', 'Infraction_TBP', 'Base_0580', 'Expenditure_RGD', 'Infraction_PBC', 'Infraction_AQO', 'Base_0229', 'Base_69608', 'Base_91828', 'Base_6852', 'Expenditure_IDZ', 'Risk_1475', 'Expenditure_BWX', 'Base_8511', 'Infraction_JYZB', 'Base_22178', 'Infraction_ZTYG', 'Infraction_ZVW', 'Infraction_EYU', 'Expenditure_UWVG', 'Base_3041', 'Payment_3207', 'Infraction_QKZN', 'Infraction_CZE', 'Base_65352', 'Risk_7095', 'Infraction_JBR', 'Base_66195', 'Base_36516', 'Infraction_RXQH', 'Infraction_HFU', 'Risk_6346', 'Expenditure_HRQ', 'Infraction_VTR', 'Risk_2102', 'Risk_4804', 'Base_7331', 'Infraction_XWX', 'Expenditure_XDD', 'Risk_4553', 'Base_67585', 'Risk_8742', 'Infraction_VHU', 'Risk_4247', 'Risk_2380', 'Infraction_GSS', 'Risk_0454', 'Base_8730', 'Expenditure_HKXV', 'Infraction_MHM', 'Risk_4160', 'Risk_3506', 'Expenditure_GCAO', 'Risk_9367', 'Base_7910', 'Expenditure_GMC', 'Risk_9423', 'Risk_6977', 'Base_9103', 'Infraction_KSBR', 'Risk_6178', 'Risk_6197', 'Infraction_NRBQ', 'Infraction_WVC', 'Infraction_QVSL', 'Infraction_QXUM', 'Risk_8532', 'Risk_9247', 'Infraction_IMIM', 'Expenditure_UIWS', 'Expenditure_ONEG', 'Expenditure_MTRQ', 'Expenditure_LAHK', 'Expenditure_HPM', 'Infraction_LTIS', 'Infraction_HFSI', 'Infraction_ETH', 'Infraction_SDWM', 'Base_5441', 'Base_2810', 'Risk_8902', 'Infraction_PTY', 'Infraction_BGGU', 'Base_4569', 'Expenditure_BEH', 'Infraction_LMHK', 'Infraction_NMCB', 'Infraction_TPAF', 'Infraction_ZRH', 'Infraction_XEPQ', 'Infraction_ZMKI', 'Infraction_WIS', 'Infraction_RKTA', 'Infraction_IIZ', 'Infraction_WVAW', 'Infraction_KEJT', 'Infraction_TFOY', 'Infraction_WMAQ', 'Infraction_SIA', 'Infraction_CZXL', 'Infraction_QEY', 'Base_52892', 'Infraction_HUK', 'Infraction_VHHP', 'Infraction_LIES', 'Risk_5270', 'Infraction_QWWW', 'Infraction_YQXM', 'Infraction_QGR', 'Infraction_LSX', 'Infraction_IBJ', 'Infraction_DNOU']\n",
      "int64: ['Base_23737']\n"
     ]
    }
   ],
   "source": [
    "# Agrupar columnas por tipo de dato\n",
    "data_types = {}\n",
    "# No hace falta comprobar todos los df ya que tienen las mismas columnas\n",
    "data_frame = df_data_part_1\n",
    "for col in data_frame.columns:\n",
    "    data_type = str(data_frame[col].dtype)\n",
    "    if data_type not in data_types:\n",
    "        data_types[data_type] = []\n",
    "    data_types[data_type].append(col)\n",
    "\n",
    "for data_type, columns in data_types.items():\n",
    "    print(f'{data_type}: {columns}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables categóricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  ID Expenditure_AHF  \\\n",
      "0  3333337004103300505242400473433643475477705348...      2017-03-05   \n",
      "1  3333337004103300505242400473433643475477705348...      2017-04-20   \n",
      "2  3333337004103300505242400473433643475477705348...      2017-05-11   \n",
      "3  3333337004103300505242400473433643475477705348...      2017-06-29   \n",
      "4  3333337004103300505242400473433643475477705348...      2017-08-03   \n",
      "\n",
      "  Infraction_YFSG Infraction_DQLY Infraction_CLH    Base_67254 Infraction_TEN  \n",
      "0              CO               O      very_high  moderate_low  extremely_low  \n",
      "1              CO               O      very_high  moderate_low  extremely_low  \n",
      "2              CO               O      very_high  moderate_low  extremely_low  \n",
      "3              CO               O      very_high  moderate_low  extremely_low  \n",
      "4              CO               O      very_high  moderate_low  extremely_low  \n"
     ]
    }
   ],
   "source": [
    "# Hacemos print de las columnas de tipo object, solo primeras filas\n",
    "data_frame = df_data_part_1\n",
    "print(data_frame.select_dtypes(include='object').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación ID to_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasamos ID a número en todos los dataframes para facilitar su procesado\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    data_frame['ID'] = pd.to_numeric(data_frame['ID'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación Expenditure_AHF to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    data_frame['Expenditure_AHF'] = pd.to_datetime(data_frame['Expenditure_AHF'], errors='coerce')\n",
    "    data_frame['Expenditure_AHF_year'] = data_frame['Expenditure_AHF'].dt.year\n",
    "    data_frame['Expenditure_AHF_month'] = data_frame['Expenditure_AHF'].dt.month\n",
    "    data_frame['Expenditure_AHF_day'] = data_frame['Expenditure_AHF'].dt.day\n",
    "    data_frame.drop(columns=['Expenditure_AHF'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación Infraction_YFSG encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CO', 'XL', 'XM', 'CL', 'CR', 'XZ'}\n"
     ]
    }
   ],
   "source": [
    "# Ver los valores de la columna Infraction_YFSG en todos los DataFrames y hacer una intersección\n",
    "unique_values = set()\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    unique_values_i = set(data_frame['Infraction_YFSG'].unique())\n",
    "    if not unique_values:\n",
    "        unique_values = unique_values_i\n",
    "    else:\n",
    "        unique_values = unique_values.intersection(unique_values_i)\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    data_frame['Infraction_YFSG_encoded'] = label_encoder.fit_transform(data_frame['Infraction_YFSG'])\n",
    "    data_frame.drop(columns=['Infraction_YFSG'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación Infraction_DQLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'U', nan, 'O', '-1', 'R'}\n"
     ]
    }
   ],
   "source": [
    "# Ver los valores de la columna Infraction_YFSG en todos los DataFrames y hacer una intersección\n",
    "unique_values = set()\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    unique_values_i = set(data_frame['Infraction_DQLY'].unique())\n",
    "    if not unique_values:\n",
    "        unique_values = unique_values_i\n",
    "    else:\n",
    "        unique_values = unique_values.intersection(unique_values_i)\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de NaNs en df_data_part_1: 3.96%\n",
      "Porcentaje de NaNs en df_data_part_2: 3.88%\n",
      "Porcentaje de NaNs en df_data_part_3: 3.98%\n",
      "Porcentaje de NaNs en df_data_part_4: 4.02%\n",
      "Porcentaje de NaNs en df_data_part_5: 3.94%\n",
      "Porcentaje de NaNs en df_data_part_6: 3.84%\n",
      "Porcentaje de NaNs en df_data_part_7: 3.93%\n"
     ]
    }
   ],
   "source": [
    "# Análisis de porcentaje de NaNs en cada DataFrame en la columna Infraction_DQLY\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    print(f'Porcentaje de NaNs en df_data_part_{i}: {data_frame[\"Infraction_DQLY\"].isna().mean() * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de codificarlo necesitamos tratar los NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48726\\AppData\\Local\\Temp\\ipykernel_18256\\2308713897.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_frame['Infraction_DQLY'].fillna(most_common_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Como el porcentaje de NaNs es muy bajo (aprox. 4%), rellenamos los NaNs con el valor más común\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    most_common_value = data_frame['Infraction_DQLY'].mode()[0]\n",
    "    data_frame['Infraction_DQLY'].fillna(most_common_value, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hacemos la codificación de la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    data_frame['Infraction_DQLY_encoded'] = label_encoder.fit_transform(data_frame['Infraction_DQLY'])\n",
    "    data_frame.drop(columns=['Infraction_DQLY'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las siguientes columnas comparten etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infraction_CLH: ['very_high' 'moderate_low' 'moderate' 'high' nan 'moderate_high'\n",
      " 'very_low' 'low']\n",
      "Base_67254: ['moderate_low' 'low' 'moderate' 'high' 'very_high' 'extremely_high'\n",
      " 'moderate_high' nan]\n",
      "Infraction_TEN: ['extremely_low' 'very_high' 'moderate_high' 'moderate_low' 'low' nan\n",
      " 'moderate' 'high']\n"
     ]
    }
   ],
   "source": [
    "ordinal_columns = ['Infraction_CLH', 'Base_67254', 'Infraction_TEN']\n",
    "\n",
    "for col in ordinal_columns:\n",
    "    print(f'{col}: {df_data_part_1[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_map = {\n",
    "    'extremely_low': 0,\n",
    "    'very_low': 1,\n",
    "    'moderate_low': 2,\n",
    "    'low': 3,\n",
    "    'moderate': 4,\n",
    "    'high':5,\n",
    "    'moderate_high': 6,\n",
    "    'very_high': 7,\n",
    "    'extremely_high': 8\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(1, 8):\n",
    "    for col in ordinal_columns:\n",
    "        data_frame = globals()[f'df_data_part_{i}']\n",
    "        data_frame[f'{col}_encoded'] = data_frame[col].map(frequency_map)\n",
    "        data_frame.drop(columns=[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infraction_CLH_encoded: [ 7.  2.  4.  5. nan  6.  1.  3.]\n",
      "Base_67254_encoded: [ 2.  3.  4.  5.  7.  8.  6. nan]\n",
      "Infraction_TEN_encoded: [ 0.  7.  6.  2.  3. nan  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "ordinal_columns = ['Infraction_CLH_encoded', 'Base_67254_encoded', 'Infraction_TEN_encoded']\n",
    "\n",
    "for col in ordinal_columns:\n",
    "    print(f'{col}: {df_data_part_1[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infraction_CLH_encoded: 3.92%\n",
      "Base_67254_encoded: 0.04%\n",
      "Infraction_TEN_encoded: 3.21%\n"
     ]
    }
   ],
   "source": [
    "# Voy a ver cuántos valores NaN hay en cada columna de las ordinal_columns en la intersection de los DataFrames como porcentaje\n",
    "for col in ordinal_columns:\n",
    "    nan_count = 0\n",
    "    total = 0\n",
    "    for i in range(1, 8):\n",
    "        data_frame = globals()[f'df_data_part_{i}']\n",
    "        total += data_frame[col].shape[0]\n",
    "        nan_count += data_frame[col].isna().sum()\n",
    "    print(f'{col}: {nan_count/total*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un porcentaje muy bajo así que podemos rellenarlos sin problema. En este caso usaremos la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infraction_CLH_encoded: [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0]\n",
      "Base_67254_encoded: [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
      "Infraction_TEN_encoded: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Quiero saber el valor que más se repite en cada columna ordinal\n",
    "for col in ordinal_columns:\n",
    "    most_common_values = []\n",
    "    for i in range(1, 8):\n",
    "        data_frame = globals()[f'df_data_part_{i}']\n",
    "        most_common_value = data_frame[col].mode()[0]\n",
    "        most_common_values.append(most_common_value)\n",
    "    print(f'{col}: {most_common_values}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN con el valor más común en cada columna ordinal.\n",
    "for col in ordinal_columns:\n",
    "    for i in range(1, 8):\n",
    "        data_frame = globals()[f'df_data_part_{i}']\n",
    "        most_common_value = data_frame[col].mode()[0]\n",
    "        data_frame[col] = data_frame[col].fillna(most_common_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay columnas duplicadas en df_data_part_1.\n",
      "No hay columnas duplicadas en df_data_part_2.\n",
      "No hay columnas duplicadas en df_data_part_3.\n",
      "No hay columnas duplicadas en df_data_part_4.\n",
      "No hay columnas duplicadas en df_data_part_5.\n",
      "No hay columnas duplicadas en df_data_part_6.\n",
      "No hay columnas duplicadas en df_data_part_7.\n"
     ]
    }
   ],
   "source": [
    "# Ya hemos visto que las categóricas no están dulpicadas entre sí así que solo analizamos si las columnas numéricas están duplicadas\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    duplicate_columns = data_frame.columns[data_frame.columns.duplicated()]\n",
    "    if not duplicate_columns.empty:\n",
    "        print(f'Columnas duplicadas en df_data_part_{i}: {duplicate_columns}')\n",
    "    else:\n",
    "        print(f'No hay columnas duplicadas en df_data_part_{i}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podemos hacer una matriz de correlación para comprobarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Vamos a hacer una matriz de correlación para ver si hay columnas altamente correlacionadas. Quiero hacer una matriz de correlación para cada DataFrame y luego compararlas para que seleccionar las columnas con correlación mayor a 0.9 y así eliminar una de ellas\n",
    "# correlation_threshold = 0.9\n",
    "# for i in range(1, 8):\n",
    "#     data_frame = globals()[f'df_data_part_{i}']\n",
    "#     corr = data_frame.corr()\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "#     sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "#     plt.title(f'Correlation Matrix df_data_part_{i}')\n",
    "#     plt.show()\n",
    "#     # ahora hacemos una lista de las columnas con correlación mayor a 0.9\n",
    "#     correlation_matrix = corr.abs()\n",
    "#     upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
    "#     if i == 1:\n",
    "#         columns_to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > correlation_threshold)]\n",
    "#     else:\n",
    "#         columns_current_matrix = [column for column in upper_triangle.columns if any(upper_triangle[column] > correlation_threshold)]\n",
    "#         #comprobar intersección de listas\n",
    "#         columns_to_drop = list(set(columns_to_drop).intersection(columns_current_matrix))\n",
    "# print(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eliminamos las columnas que tengar correlación mayor a 0.9 o -0.9\n",
    "# correlation_threshold = 0.9\n",
    "# correlation_matrix = df_data_part_1.corr().abs()\n",
    "# upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool))\n",
    "# columns_to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > correlation_threshold)]\n",
    "# print(f'Columnas a eliminar: {columns_to_drop}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a analizar las filas para eliminar aquellas que tengan NaN en más del 30% de las columnas si estas componen una pequeña poción del dataframe y rellenar estos valores no tendría sentido ya que la fila perdería valor para el posterior estudio ya que sería completamente artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas a eliminar: 0.26%\n"
     ]
    }
   ],
   "source": [
    "# Quiero saber cuántas filas tienen más del 30% de las columnas nulas en porcentaje sobre el total de todos los DataFrames\n",
    "rows_to_drop = []\n",
    "total_rows = 0\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    total_rows += data_frame.shape[0]\n",
    "    null_percentage = data_frame.isnull().mean(axis=1) * 100\n",
    "    rows_to_drop.extend(null_percentage[null_percentage > 30].index)\n",
    "rows_to_drop = set(rows_to_drop)\n",
    "print(f'Número de filas a eliminar: {len(rows_to_drop)/total_rows*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminos las filas con más del 30% de valores nulos\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    # Como no me deja usar los valores de rows_to_drop como índices, lo hago de la siguiente manera\n",
    "    data_frame.drop(data_frame.index.intersection(rows_to_drop), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a hacer un análisis de las columnas que nos quedan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment_6804: 0.57285%\n",
      "Base_80863: 0.00515%\n",
      "Expenditure_JIG: 18.28497%\n",
      "Infraction_SNZ: 0.00515%\n",
      "Base_02683: 0.00515%\n",
      "Infraction_ZWWJ: 29.85362%\n",
      "Infraction_QJJF: 4.71919%\n",
      "Infraction_EJZ: 0.00515%\n",
      "Infraction_FMXQ: 21.68924%\n",
      "Infraction_TLPJ: 12.72720%\n",
      "Base_1165: 0.00009%\n",
      "Base_6187: 0.37812%\n",
      "Infraction_AYWV: 0.27658%\n",
      "Payment_22507: 5.22159%\n",
      "Infraction_PAS: 0.00515%\n",
      "Expenditure_HMO: 18.28497%\n",
      "Infraction_BSU: 3.13283%\n",
      "Base_14808: 0.75777%\n",
      "Infraction_HSSU: 1.70469%\n",
      "Infraction_TBP: 10.71778%\n",
      "Base_0580: 0.05267%\n",
      "Infraction_PBC: 13.51881%\n",
      "Base_0229: 0.00515%\n",
      "Base_91828: 0.00515%\n",
      "Base_6852: 0.00515%\n",
      "Infraction_JYZB: 3.27808%\n",
      "Base_22178: 0.00515%\n",
      "Infraction_ZTYG: 1.46566%\n",
      "Infraction_EYU: 0.17689%\n",
      "Infraction_QKZN: 0.28817%\n",
      "Risk_7095: 0.00003%\n",
      "Infraction_JBR: 45.50540%\n",
      "Base_66195: 0.05267%\n",
      "Base_36516: 0.00515%\n",
      "Infraction_RXQH: 4.71919%\n",
      "Infraction_HFU: 1.12025%\n",
      "Infraction_VTR: 0.28817%\n",
      "Base_7331: 0.00515%\n",
      "Infraction_XWX: 0.22756%\n",
      "Risk_4553: 0.00074%\n",
      "Infraction_VHU: 3.27808%\n",
      "Risk_4247: 0.00003%\n",
      "Infraction_GSS: 0.27658%\n",
      "Base_8730: 0.00515%\n",
      "Risk_9423: 0.00120%\n",
      "Base_9103: 0.00515%\n",
      "Infraction_KSBR: 0.27658%\n",
      "Infraction_NRBQ: 2.63359%\n",
      "Expenditure_UIWS: 0.34234%\n",
      "Expenditure_ONEG: 0.00788%\n",
      "Expenditure_MTRQ: 0.33483%\n",
      "Expenditure_LAHK: 0.23238%\n",
      "Expenditure_HPM: 0.01147%\n",
      "Infraction_LTIS: 0.52778%\n",
      "Infraction_HFSI: 1.58240%\n",
      "Infraction_ETH: 1.58240%\n",
      "Infraction_SDWM: 1.58240%\n",
      "Base_2810: 0.00110%\n",
      "Risk_8902: 2.24443%\n",
      "Infraction_PTY: 0.01196%\n",
      "Infraction_BGGU: 0.01662%\n",
      "Base_4569: 0.00104%\n",
      "Expenditure_BEH: 25.07885%\n",
      "Infraction_LMHK: 2.95426%\n",
      "Infraction_NMCB: 2.95426%\n",
      "Infraction_TPAF: 2.95426%\n",
      "Infraction_ZRH: 2.95426%\n",
      "Infraction_XEPQ: 2.95426%\n",
      "Infraction_ZMKI: 2.95426%\n",
      "Infraction_WIS: 2.95426%\n",
      "Infraction_RKTA: 2.95426%\n",
      "Infraction_IIZ: 2.95426%\n",
      "Infraction_WVAW: 2.95426%\n",
      "Infraction_KEJT: 2.95426%\n",
      "Infraction_TFOY: 2.95426%\n",
      "Infraction_WMAQ: 1.91497%\n",
      "Infraction_CZXL: 1.58240%\n",
      "Infraction_QEY: 1.58240%\n",
      "Base_52892: 0.01220%\n",
      "Infraction_HUK: 1.58240%\n",
      "Infraction_VHHP: 1.58240%\n",
      "Infraction_LIES: 0.56417%\n",
      "Infraction_QWWW: 1.58240%\n",
      "Infraction_YQXM: 0.52736%\n",
      "Infraction_QGR: 1.58240%\n",
      "Infraction_LSX: 1.58240%\n",
      "Infraction_IBJ: 0.52852%\n",
      "Infraction_DNOU: 1.58240%\n"
     ]
    }
   ],
   "source": [
    "# Voy a ver cuántos valores NaN hay en cada columna en la intersection de los DataFrames.\n",
    "columns_percentage = {}\n",
    "for col in df_data_part_1.columns:\n",
    "    nan_count = 0\n",
    "    total_rows = 0\n",
    "    for i in range(1, 8):\n",
    "        data_frame = globals()[f'df_data_part_{i}']\n",
    "        total_rows += data_frame.shape[0]\n",
    "        nan_count += data_frame[col].isna().sum()\n",
    "    if nan_count > 0:\n",
    "        columns_percentage[col] = nan_count/total_rows * 100    \n",
    "        print(f'{col}: {nan_count/total_rows * 100:.5f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a rellenar aquellas que tengan menos del 6% de NaNs y a eliminar los que tengan más de ese porcentaje , rellenar estos últimos no tendría sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las columnas con más de 6% de valores nulos en la intersección de los DataFrames\n",
    "for col in columns_percentage.keys():\n",
    "    if columns_percentage[col] > 6:\n",
    "        for i in range(1, 8):\n",
    "            data_frame = globals()[f'df_data_part_{i}']\n",
    "            data_frame.drop(columns=[col], inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a rellenar los NaNs de las columnas restantes de la siguiente manera:\n",
    "# Si la columna es categórica, rellena con la moda (no hace falta tenerlo en cuenta ahora ya que lo hemos hecho manualmnete anteriormente)\n",
    "# Si la columna es numérica:\n",
    "#           - con la media si la desviación estándar es menor a 1\n",
    "#           - con la mediana si la desviación estándar es mayor a 1\n",
    "#           - con la moda si la desviación estándar es 0\n",
    "\n",
    "for col in df_data_part_1.columns:\n",
    "    for i in range(1, 8):\n",
    "        data_frame = globals()[f'df_data_part_{i}']\n",
    "        if data_frame[col].isna().sum() != 0:\n",
    "            mean = data_frame[col].mean()\n",
    "            median = data_frame[col].median()\n",
    "            mode = data_frame[col].mode()[0]\n",
    "            std = data_frame[col].std()\n",
    "            if std == 0:\n",
    "                data_frame[col] = data_frame[col].fillna(mode)\n",
    "            elif std < 1:\n",
    "                data_frame[col] = data_frame[col].fillna(mean)\n",
    "            else:\n",
    "                data_frame[col] = data_frame[col].fillna(median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratar valores infinitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores infinitos en df_data_part_1: 0.0\n",
      "Valores infinitos en df_data_part_2: 0.0\n",
      "Valores infinitos en df_data_part_3: 0.0\n",
      "Valores infinitos en df_data_part_4: 0.0\n",
      "Valores infinitos en df_data_part_5: 0.0\n",
      "Valores infinitos en df_data_part_6: 0.0\n",
      "Valores infinitos en df_data_part_7: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los valores infinitos para tratarlos\n",
    "from numpy import inf\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    infinite_values = data_frame[data_frame == np.inf].sum().sum()\n",
    "    print(f'Valores infinitos en df_data_part_{i}: {infinite_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de características\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3333337004103300505242400473433643475477705348...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3333412724050477534287115505554450368233003786...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3333755354307801420025735367852078550468735254...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3333545238615133608512002405572210535308150267...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3333333216773173414240337455254307444633113087...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  label\n",
       "0  3333337004103300505242400473433643475477705348...      0\n",
       "1  3333412724050477534287115505554450368233003786...      0\n",
       "2  3333755354307801420025735367852078550468735254...      0\n",
       "3  3333545238615133608512002405572210535308150267...      0\n",
       "4  3333333216773173414240337455254307444633113087...      1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels_50 = pd.read_csv('../data/train_labels_50_lines.csv', encoding='ISO-8859-1')\n",
    "df_labels_50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la variable objetivo es binaria (0,1), probamos con ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv('train_labels.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels['ID'] = pd.to_numeric(df_labels['ID'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO EJECUTAR más de una vez (pasan cosas raras con label)\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    globals()[f'df_merged_part_{i}'] = pd.merge(data_frame, df_labels, on='ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La partición 1 tiene la columna label.\n",
      "La partición 2 tiene la columna label.\n",
      "La partición 3 tiene la columna label.\n",
      "La partición 4 tiene la columna label.\n",
      "La partición 5 tiene la columna label.\n",
      "La partición 6 tiene la columna label.\n",
      "La partición 7 tiene la columna label.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_merged_part_{i}']\n",
    "    if 'label' not in data_frame.columns:\n",
    "        print(f'La partición {i} no tiene la columna label.')\n",
    "    else:\n",
    "        print(f'La partición {i} tiene la columna label.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas {'Base_80863', 'Payment_6804', 'Base_85131', 'Infraction_QJJF', 'Base_69608'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif \n",
    "\n",
    "columns_data = df_data_part_1.columns\n",
    "selected_features = set()\n",
    "\n",
    "# Como el train data está dividido en 7 partes, vamos a hacer un loop para cargar cada parte y seleccionar las 5 características más importantes según ANOVA (f_classif)\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_merged_part_{i}']\n",
    "        \n",
    "    X = data_frame.drop(columns=['label']).copy()\n",
    "    y = data_frame['label']\n",
    "    \n",
    "    selector = SelectKBest(score_func=f_classif, k=5)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    if i == 1:\n",
    "        selected_features = set(columns_data[selected_indices])\n",
    "    else:\n",
    "        selected_features.intersection(set(data_frame.columns[selected_indices]))\n",
    "\n",
    "print(f'Características seleccionadas {selected_features}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# #scale data for each dataframe\n",
    "# scaler = StandardScaler()\n",
    "# for i in range(1, 8):\n",
    "#     data_frame = globals()[f'df_data_part_{i}']\n",
    "#     data_frame_scaled = pd.DataFrame(scaler.fit_transform(data_frame), columns=data_frame.columns)\n",
    "#     globals()[f'df_data_part_{i}'] = data_frame_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_frame = df_data_part_1\n",
    "data_frame_merged = pd.merge(data_frame, df_labels, on='ID', how='inner')\n",
    "x = data_frame\n",
    "y = data_frame_merged['label']\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "    \n",
    "model = LogisticRegression(max_iter=3000, solver='saga') #soltion for big datasets\n",
    "rfe = RFE(estimator=model, n_features_to_select=5)\n",
    "X_rfe = rfe.fit_transform(x_scaled, y)\n",
    "selected_indices = rfe.get_support(indices=True)\n",
    "selected_features = data_frame_merged.columns[selected_indices]\n",
    "S\n",
    "print(f'Wybrane cechy w df_data_part_{i}: {selected_features}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8000\u001b[39m)\n\u001b[0;32m     10\u001b[0m rfe \u001b[38;5;241m=\u001b[39m RFE(model, n_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m fit \u001b[38;5;241m=\u001b[39m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m selected_indices \u001b[38;5;241m=\u001b[39m rfe\u001b[38;5;241m.\u001b[39mget_support(indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m data_frame\u001b[38;5;241m.\u001b[39mcolumns[selected_indices]\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:264\u001b[0m, in \u001b[0;36mRFE.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:311\u001b[0m, in \u001b[0;36mRFE._fit\u001b[1;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[1;32m--> 311\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[0;32m    314\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[0;32m    315\u001b[0m     estimator,\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[0;32m    317\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    318\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1296\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1321\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:455\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    451\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (C \u001b[38;5;241m*\u001b[39m sw_sum)\n\u001b[0;32m    452\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    453\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    454\u001b[0m ]\n\u001b[1;32m--> 455\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mftol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    470\u001b[0m     solver,\n\u001b[0;32m    471\u001b[0m     opt_res,\n\u001b[0;32m    472\u001b[0m     max_iter,\n\u001b[0;32m    473\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    474\u001b[0m )\n\u001b[0;32m    475\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:713\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 713\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    716\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    401\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:296\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:262\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:163\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:145\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     78\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 73\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:296\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    294\u001b[0m     grad[:n_features] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m grad_pointwise \u001b[38;5;241m+\u001b[39m l2_reg_strength \u001b[38;5;241m*\u001b[39m weights\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept:\n\u001b[1;32m--> 296\u001b[0m         grad[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_pointwise\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    298\u001b[0m     grad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_classes, n_dof), dtype\u001b[38;5;241m=\u001b[39mweights\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#perform wrapper method for feature selection for df1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_frame = df_data_part_1\n",
    "data_frame_merged = pd.merge(data_frame, df_labels, on='ID', how='inner')\n",
    "x = data_frame\n",
    "y = data_frame_merged['label']\n",
    "model = LogisticRegression(max_iter=8000)\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "fit = rfe.fit(x, y)\n",
    "selected_indices = rfe.get_support(indices=True)\n",
    "selected_features = data_frame.columns[selected_indices]\n",
    "print(f'Características seleccionadas en df_data_part_1: {selected_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\48726\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# #perform wrapper method for feature selection\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Como el train data está dividido en 7 partes, vamos a hacer un loop para cargar cada parte y seleccionar las 5 características más importantes según RFE\n",
    "# for i in range(1, 8):\n",
    "#     data_frame = globals()[f'df_data_part_{i}']\n",
    "#     data_frame_merged = pd.merge(data_frame, df_labels, on='ID', how='inner')\n",
    "    \n",
    "#     x = data_frame\n",
    "#     y = data_frame_merged['label']\n",
    "#     estimator = LogisticRegression()\n",
    "#     selector = RFE(estimator, n_features_to_select=5)\n",
    "#     X_new = selector.fit_transform(x, y)\n",
    "#     selected_indices = selector.get_support(indices=True)\n",
    "#     selected_features = data_frame.columns[selected_indices]\n",
    "\n",
    "#     print(f'Características seleccionadas en df_data_part_{i}: {selected_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embebido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora de Hiperparámetros (optuna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es imposible procesar tantos datos con cross validation y el resto de métodos, intento al máximo reducir previamente el número de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a hacer una selección de características a eliminar con el método de la varianza (threshold=0.01)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_merged_part_{i}']\n",
    "\n",
    "    X = data_frame.drop(columns=['label']).copy()\n",
    "    y = data_frame['label']\n",
    "\n",
    "    selector = VarianceThreshold(threshold=0.01)\n",
    "    selector.fit(X)\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "    if i == 1:\n",
    "        selected_features = set(columns_data[selected_indices])\n",
    "    else:\n",
    "        selected_features.intersection(set(data_frame.columns[selected_indices]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haz media y mediana de estos datos y en el código de thershold + anova ajusta el umbral de anova*************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partición 1:\n",
      "Columna: Payment_6804, Score ANOVA: 291860.4758180822\n",
      "Columna: Base_69608, Score ANOVA: 153541.54780919952\n",
      "Columna: Base_80863, Score ANOVA: 149990.1699224818\n",
      "Columna: Base_85131, Score ANOVA: 139342.15167214588\n",
      "Columna: Infraction_QJJF, Score ANOVA: 129819.03346945567\n",
      "Columna: Base_9103, Score ANOVA: 127860.21393997248\n",
      "Columna: Infraction_CZE, Score ANOVA: 127544.63700975334\n",
      "Columna: Infraction_BSU, Score ANOVA: 125100.258513161\n",
      "Columna: Infraction_ZYW, Score ANOVA: 122777.34360940335\n",
      "Columna: Base_02683, Score ANOVA: 113412.0376286579\n",
      "Columna: Base_67254_encoded, Score ANOVA: 112592.56901749858\n",
      "Columna: Base_39598, Score ANOVA: 110017.47919121657\n",
      "Columna: Base_3041, Score ANOVA: 105191.80338837358\n",
      "Columna: Infraction_QKZN, Score ANOVA: 103400.27158688453\n",
      "Columna: Base_76065, Score ANOVA: 95169.34306937229\n",
      "Columna: Base_0229, Score ANOVA: 91742.75883282853\n",
      "Columna: Base_7744, Score ANOVA: 91140.72615342418\n",
      "Columna: Base_2810, Score ANOVA: 89494.43236142136\n",
      "Columna: Base_91828, Score ANOVA: 89452.97008990633\n",
      "Columna: Base_6852, Score ANOVA: 82782.15745250501\n",
      "Columna: Base_36384, Score ANOVA: 80313.06514972438\n",
      "Columna: Base_22178, Score ANOVA: 79352.30108021967\n",
      "Columna: Risk_1930, Score ANOVA: 74865.28358249708\n",
      "Columna: Base_8730, Score ANOVA: 70054.61067295812\n",
      "Columna: Base_6187, Score ANOVA: 57247.034287980925\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 47783.782583451975\n",
      "Columna: Risk_9995, Score ANOVA: 43869.51351736358\n",
      "Columna: Infraction_GGO, Score ANOVA: 41610.8025978129\n",
      "Columna: Risk_8902, Score ANOVA: 39874.11032395695\n",
      "Columna: Infraction_EJZ, Score ANOVA: 37874.8313876514\n",
      "Columna: Risk_0322, Score ANOVA: 36437.78600755956\n",
      "Columna: Infraction_RXQH, Score ANOVA: 35944.646257989814\n",
      "Columna: Infraction_SNZ, Score ANOVA: 32100.633861270562\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 32016.488548548714\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 31088.37463976755\n",
      "Columna: Payment_3207, Score ANOVA: 29782.843333921268\n",
      "Columna: Base_67585, Score ANOVA: 29125.527171519167\n",
      "Columna: Infraction_VHHP, Score ANOVA: 28554.712230325185\n",
      "Columna: Risk_2102, Score ANOVA: 27922.402728795663\n",
      "Columna: Payment_22507, Score ANOVA: 27760.251410244757\n",
      "Columna: Infraction_AYWV, Score ANOVA: 26672.797301564675\n",
      "Columna: Infraction_HFU, Score ANOVA: 26247.370520866516\n",
      "Columna: Infraction_BGGU, Score ANOVA: 25646.713042281124\n",
      "Columna: Risk_0003, Score ANOVA: 24979.110976026364\n",
      "Columna: Infraction_HUK, Score ANOVA: 22634.42510844602\n",
      "Columna: Infraction_HSSU, Score ANOVA: 19162.83686570571\n",
      "Columna: Infraction_NMCB, Score ANOVA: 18769.313494778144\n",
      "Columna: Infraction_GSS, Score ANOVA: 18706.85032675008\n",
      "Columna: Infraction_WIS, Score ANOVA: 18685.350916933443\n",
      "Columna: Base_66195, Score ANOVA: 18453.807892444092\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 18203.31313946355\n",
      "Columna: Infraction_CZXL, Score ANOVA: 18162.266241920282\n",
      "Columna: Infraction_CGP, Score ANOVA: 16849.609551713747\n",
      "Columna: Infraction_SIA, Score ANOVA: 16489.780328670637\n",
      "Columna: Infraction_XWX, Score ANOVA: 16251.997115848093\n",
      "Columna: Infraction_EYU, Score ANOVA: 16154.983760134002\n",
      "Columna: Infraction_TPAF, Score ANOVA: 15413.85566613092\n",
      "Columna: Risk_8065, Score ANOVA: 14776.014273540957\n",
      "Columna: Infraction_RKTA, Score ANOVA: 14217.61130420138\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 13931.717857667498\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 13865.602796345125\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 13663.211634732384\n",
      "Columna: Infraction_IIZ, Score ANOVA: 12504.03239746183\n",
      "Columna: Risk_6977, Score ANOVA: 12362.193459615815\n",
      "Columna: Risk_6346, Score ANOVA: 12324.087617653087\n",
      "Columna: Infraction_LMHK, Score ANOVA: 11704.266045425982\n",
      "Columna: Risk_8532, Score ANOVA: 11391.568166256615\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 11079.052623859194\n",
      "Columna: Infraction_WVC, Score ANOVA: 10979.027523384844\n",
      "Columna: Infraction_LIES, Score ANOVA: 10370.716546775591\n",
      "Columna: Risk_4553, Score ANOVA: 10264.912228409308\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 10006.411672090413\n",
      "Columna: Infraction_QEY, Score ANOVA: 9609.483187038279\n",
      "Columna: Infraction_PAS, Score ANOVA: 8984.702261589442\n",
      "Columna: Expenditure_GMC, Score ANOVA: 8982.44762919085\n",
      "Columna: Risk_0454, Score ANOVA: 8591.401139910335\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 8579.22282178895\n",
      "Columna: Infraction_LSX, Score ANOVA: 8464.063762277943\n",
      "Columna: Infraction_QWWW, Score ANOVA: 8453.60659670286\n",
      "Columna: Infraction_QGR, Score ANOVA: 8050.059796413943\n",
      "Columna: Risk_2380, Score ANOVA: 7884.9485217672245\n",
      "Columna: Infraction_YQXM, Score ANOVA: 7629.981566535569\n",
      "Columna: Infraction_HFSI, Score ANOVA: 7490.98832970326\n",
      "Columna: Infraction_ETH, Score ANOVA: 7410.046390447629\n",
      "Columna: Infraction_SDWM, Score ANOVA: 7311.220044324874\n",
      "Columna: Infraction_DNOU, Score ANOVA: 6964.302170042817\n",
      "Columna: Base_65352, Score ANOVA: 6612.784022738711\n",
      "Columna: Risk_9423, Score ANOVA: 6556.506340284287\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 6538.308529193371\n",
      "Columna: Infraction_KSBR, Score ANOVA: 6065.707670019351\n",
      "Columna: Risk_1475, Score ANOVA: 5908.565208212724\n",
      "Columna: Risk_9367, Score ANOVA: 5636.980554909188\n",
      "Columna: Expenditure_BWX, Score ANOVA: 5244.336804203631\n",
      "Columna: Expenditure_FIP, Score ANOVA: 5148.910654044799\n",
      "Columna: Risk_8742, Score ANOVA: 4955.017866018027\n",
      "Columna: Base_1039, Score ANOVA: 4790.68563613835\n",
      "Columna: Base_7910, Score ANOVA: 4744.48940916663\n",
      "Columna: Risk_4804, Score ANOVA: 4738.9946066245975\n",
      "Columna: Infraction_AQO, Score ANOVA: 4393.156059149585\n",
      "Columna: Base_8511, Score ANOVA: 4383.751940662774\n",
      "Columna: Base_52892, Score ANOVA: 4360.354117370724\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 4023.1915286293734\n",
      "Columna: Base_1165, Score ANOVA: 3797.2230500537344\n",
      "Columna: Expenditure_RGD, Score ANOVA: 3661.1355567503792\n",
      "Columna: Base_6872, Score ANOVA: 3581.254541653695\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 3458.311582254312\n",
      "Columna: Infraction_VHU, Score ANOVA: 3431.344966521123\n",
      "Columna: Infraction_ZVW, Score ANOVA: 3276.359987265917\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 3217.779229120679\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 3192.6649824650463\n",
      "Columna: Risk_4160, Score ANOVA: 2780.8743905573983\n",
      "Columna: Infraction_EHZP, Score ANOVA: 2728.413610254467\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 2513.0207626895626\n",
      "Columna: Infraction_QXUM, Score ANOVA: 2461.42697965793\n",
      "Columna: Infraction_MHM, Score ANOVA: 2376.284408467256\n",
      "Columna: Risk_9247, Score ANOVA: 2050.3274583373172\n",
      "Columna: Infraction_IMIM, Score ANOVA: 1961.879395772768\n",
      "Columna: Infraction_TFOY, Score ANOVA: 1898.3339589899758\n",
      "Columna: Infraction_WVAW, Score ANOVA: 1875.6466267897342\n",
      "Columna: Infraction_VTR, Score ANOVA: 1824.450418141412\n",
      "Columna: Risk_7095, Score ANOVA: 1819.175847772957\n",
      "Columna: Risk_6178, Score ANOVA: 1787.29188153056\n",
      "Columna: Base_23737, Score ANOVA: 1783.7486311035304\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1486.6167918465594\n",
      "Columna: Base_24406, Score ANOVA: 1467.5743316899977\n",
      "Columna: Expenditure_HPM, Score ANOVA: 1090.5113754088343\n",
      "Columna: Base_5441, Score ANOVA: 1063.4804715036828\n",
      "Columna: Expenditure_YTR, Score ANOVA: 1058.7310112509986\n",
      "Columna: Base_14808, Score ANOVA: 828.0306367743035\n",
      "Columna: Risk_4247, Score ANOVA: 736.4135010320747\n",
      "Columna: Infraction_QVSL, Score ANOVA: 735.1150602331007\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 515.2888559722373\n",
      "Columna: Expenditure_XDD, Score ANOVA: 460.4535883770258\n",
      "Columna: Infraction_ZRH, Score ANOVA: 437.8370779355966\n",
      "Columna: Base_36516, Score ANOVA: 348.0096294623533\n",
      "Columna: Infraction_LTIS, Score ANOVA: 266.9906025421592\n",
      "Columna: Risk_5270, Score ANOVA: 208.56272288388303\n",
      "Columna: Infraction_PTY, Score ANOVA: 164.70533024858673\n",
      "Columna: Risk_6197, Score ANOVA: 115.1039452154667\n",
      "Columna: Base_0580, Score ANOVA: 88.12379646695\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 81.13739452761949\n",
      "Columna: Base_9516, Score ANOVA: 60.27499513081744\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 56.81634518455092\n",
      "Columna: Base_4569, Score ANOVA: 47.11155744835318\n",
      "Columna: Infraction_JYZB, Score ANOVA: 46.89055736188288\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 34.784291643066105\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 17.761381284923726\n",
      "Columna: Infraction_IBJ, Score ANOVA: 16.209682068325492\n",
      "Columna: Base_7331, Score ANOVA: 11.53411963850557\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 9.07533281077828\n",
      "Columna: ID, Score ANOVA: 3.407345655131743\n",
      "Columna: Risk_3506, Score ANOVA: 0.6696897777005743\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 0.4919508450781647\n",
      "\n",
      "\n",
      "Partición 2:\n",
      "Columna: Payment_6804, Score ANOVA: 287303.20863689535\n",
      "Columna: Base_69608, Score ANOVA: 152544.42539708343\n",
      "Columna: Base_80863, Score ANOVA: 148861.63738502288\n",
      "Columna: Base_85131, Score ANOVA: 143943.38462449447\n",
      "Columna: Infraction_QJJF, Score ANOVA: 132245.39850228076\n",
      "Columna: Infraction_CZE, Score ANOVA: 128545.75119862922\n",
      "Columna: Base_9103, Score ANOVA: 126707.1233624827\n",
      "Columna: Infraction_BSU, Score ANOVA: 123220.06050908941\n",
      "Columna: Infraction_ZYW, Score ANOVA: 122492.1253266916\n",
      "Columna: Base_39598, Score ANOVA: 111612.53767986795\n",
      "Columna: Base_67254_encoded, Score ANOVA: 111001.59928162953\n",
      "Columna: Base_02683, Score ANOVA: 110530.67579106157\n",
      "Columna: Base_3041, Score ANOVA: 106640.08299176316\n",
      "Columna: Infraction_QKZN, Score ANOVA: 104920.00807986387\n",
      "Columna: Base_76065, Score ANOVA: 94771.25195085515\n",
      "Columna: Base_0229, Score ANOVA: 92241.28553147834\n",
      "Columna: Base_7744, Score ANOVA: 87913.40415727069\n",
      "Columna: Base_2810, Score ANOVA: 86440.37288066461\n",
      "Columna: Base_91828, Score ANOVA: 86393.24754976036\n",
      "Columna: Base_6852, Score ANOVA: 84717.09065822422\n",
      "Columna: Base_36384, Score ANOVA: 77094.45828661973\n",
      "Columna: Base_22178, Score ANOVA: 76192.7242099509\n",
      "Columna: Risk_1930, Score ANOVA: 75589.36149892266\n",
      "Columna: Base_8730, Score ANOVA: 69173.47527764857\n",
      "Columna: Base_6187, Score ANOVA: 59312.116461343125\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 48265.25236190827\n",
      "Columna: Risk_9995, Score ANOVA: 44491.99679509578\n",
      "Columna: Infraction_GGO, Score ANOVA: 41541.75193349076\n",
      "Columna: Risk_8902, Score ANOVA: 40894.59656561918\n",
      "Columna: Infraction_EJZ, Score ANOVA: 40061.92773131451\n",
      "Columna: Infraction_RXQH, Score ANOVA: 36210.86110053425\n",
      "Columna: Risk_0322, Score ANOVA: 35211.69984623015\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 33737.911962103644\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 32882.308299792065\n",
      "Columna: Infraction_SNZ, Score ANOVA: 29784.704668058283\n",
      "Columna: Payment_3207, Score ANOVA: 28674.334277554644\n",
      "Columna: Risk_2102, Score ANOVA: 28290.403775826417\n",
      "Columna: Infraction_VHHP, Score ANOVA: 27731.8511142724\n",
      "Columna: Base_67585, Score ANOVA: 27615.777615660412\n",
      "Columna: Payment_22507, Score ANOVA: 26815.436158912406\n",
      "Columna: Infraction_AYWV, Score ANOVA: 26515.736371706367\n",
      "Columna: Risk_0003, Score ANOVA: 24930.87136767792\n",
      "Columna: Infraction_HFU, Score ANOVA: 24029.18976449776\n",
      "Columna: Infraction_HUK, Score ANOVA: 23126.510741403737\n",
      "Columna: Infraction_BGGU, Score ANOVA: 22791.12457148616\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 19665.908471851428\n",
      "Columna: Infraction_CZXL, Score ANOVA: 19032.238114313037\n",
      "Columna: Infraction_HSSU, Score ANOVA: 18742.313325492465\n",
      "Columna: Base_66195, Score ANOVA: 17832.213861374552\n",
      "Columna: Infraction_WIS, Score ANOVA: 17490.81801963703\n",
      "Columna: Infraction_NMCB, Score ANOVA: 17295.658774107964\n",
      "Columna: Infraction_GSS, Score ANOVA: 16983.692820454646\n",
      "Columna: Infraction_SIA, Score ANOVA: 16710.361339043564\n",
      "Columna: Infraction_EYU, Score ANOVA: 16070.475741675664\n",
      "Columna: Infraction_XWX, Score ANOVA: 15836.016856504335\n",
      "Columna: Infraction_CGP, Score ANOVA: 15379.934497658478\n",
      "Columna: Infraction_TPAF, Score ANOVA: 15133.014520937922\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 14351.91941826453\n",
      "Columna: Infraction_RKTA, Score ANOVA: 14201.097087030104\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 14139.823546286183\n",
      "Columna: Risk_8065, Score ANOVA: 13273.208415154018\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 13143.08139655866\n",
      "Columna: Risk_6977, Score ANOVA: 12947.164710595835\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 12516.831009935084\n",
      "Columna: Infraction_LMHK, Score ANOVA: 12245.563052154144\n",
      "Columna: Risk_6346, Score ANOVA: 11162.158544446707\n",
      "Columna: Infraction_IIZ, Score ANOVA: 11117.352790709447\n",
      "Columna: Infraction_WVC, Score ANOVA: 10953.858789479418\n",
      "Columna: Risk_8532, Score ANOVA: 10637.375379580993\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 10036.087709245481\n",
      "Columna: Expenditure_GMC, Score ANOVA: 9629.158971652343\n",
      "Columna: Infraction_LIES, Score ANOVA: 9542.904688330967\n",
      "Columna: Infraction_QEY, Score ANOVA: 9469.885262373109\n",
      "Columna: Risk_4553, Score ANOVA: 9042.557973955301\n",
      "Columna: Risk_0454, Score ANOVA: 8787.957497783485\n",
      "Columna: Infraction_PAS, Score ANOVA: 8497.955421256147\n",
      "Columna: Infraction_QWWW, Score ANOVA: 8410.839294480613\n",
      "Columna: Infraction_LSX, Score ANOVA: 8401.231242607704\n",
      "Columna: Risk_2380, Score ANOVA: 8320.205950733294\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 8099.96955962629\n",
      "Columna: Infraction_DNOU, Score ANOVA: 8080.947931304598\n",
      "Columna: Infraction_QGR, Score ANOVA: 7970.107427191062\n",
      "Columna: Infraction_HFSI, Score ANOVA: 7300.997661411421\n",
      "Columna: Infraction_ETH, Score ANOVA: 7219.408664741986\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 7057.761843074866\n",
      "Columna: Infraction_YQXM, Score ANOVA: 6762.801316129061\n",
      "Columna: Infraction_SDWM, Score ANOVA: 6626.985504607261\n",
      "Columna: Risk_1475, Score ANOVA: 6534.7591779285185\n",
      "Columna: Infraction_KSBR, Score ANOVA: 6028.569528359947\n",
      "Columna: Expenditure_BWX, Score ANOVA: 5872.31310686483\n",
      "Columna: Risk_9423, Score ANOVA: 5812.311007348186\n",
      "Columna: Base_65352, Score ANOVA: 5479.42086136856\n",
      "Columna: Base_7910, Score ANOVA: 5133.801686279585\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 5118.471993093726\n",
      "Columna: Expenditure_FIP, Score ANOVA: 5116.3779113183\n",
      "Columna: Risk_8742, Score ANOVA: 4880.71257167619\n",
      "Columna: Risk_9367, Score ANOVA: 4599.502540762848\n",
      "Columna: Base_8511, Score ANOVA: 4348.045699022805\n",
      "Columna: Base_52892, Score ANOVA: 4337.092774305929\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 4330.478672505626\n",
      "Columna: Risk_4804, Score ANOVA: 4192.043992324323\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 3893.991787631132\n",
      "Columna: Base_1039, Score ANOVA: 3841.9199699489973\n",
      "Columna: Expenditure_RGD, Score ANOVA: 3837.9582792517217\n",
      "Columna: Infraction_ZVW, Score ANOVA: 3658.949661480516\n",
      "Columna: Base_1165, Score ANOVA: 3369.161768319138\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 3034.354345555599\n",
      "Columna: Infraction_EHZP, Score ANOVA: 2939.566259119227\n",
      "Columna: Infraction_VHU, Score ANOVA: 2867.979321823978\n",
      "Columna: Base_6872, Score ANOVA: 2866.5067299863604\n",
      "Columna: Risk_7095, Score ANOVA: 2713.3266953502944\n",
      "Columna: Infraction_AQO, Score ANOVA: 2633.5958236902115\n",
      "Columna: Infraction_MHM, Score ANOVA: 2590.1900332880923\n",
      "Columna: Risk_4160, Score ANOVA: 2506.9692250220323\n",
      "Columna: Infraction_QXUM, Score ANOVA: 2440.9626047230386\n",
      "Columna: Infraction_TFOY, Score ANOVA: 2335.540029736866\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 2236.539803210218\n",
      "Columna: Risk_6178, Score ANOVA: 2019.213392803226\n",
      "Columna: Base_24406, Score ANOVA: 1959.3481904750258\n",
      "Columna: Risk_9247, Score ANOVA: 1881.1577358864488\n",
      "Columna: Infraction_WVAW, Score ANOVA: 1841.5250438321166\n",
      "Columna: Infraction_IMIM, Score ANOVA: 1764.1323894246204\n",
      "Columna: Base_23737, Score ANOVA: 1712.676404240004\n",
      "Columna: Infraction_VTR, Score ANOVA: 1499.2502037308848\n",
      "Columna: Expenditure_YTR, Score ANOVA: 1456.8067705153915\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1219.1795303635693\n",
      "Columna: Base_14808, Score ANOVA: 1147.3495971289321\n",
      "Columna: Expenditure_HPM, Score ANOVA: 925.8067118966478\n",
      "Columna: Base_5441, Score ANOVA: 916.2863890185934\n",
      "Columna: Infraction_QVSL, Score ANOVA: 628.208627700363\n",
      "Columna: Risk_4247, Score ANOVA: 552.3583244302941\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 486.22899164803107\n",
      "Columna: Expenditure_XDD, Score ANOVA: 324.3163400834218\n",
      "Columna: Risk_5270, Score ANOVA: 323.9388241177728\n",
      "Columna: Infraction_ZRH, Score ANOVA: 279.44190678779546\n",
      "Columna: Base_36516, Score ANOVA: 203.41205313921603\n",
      "Columna: Base_9516, Score ANOVA: 183.9597519318554\n",
      "Columna: Risk_6197, Score ANOVA: 181.75798808026065\n",
      "Columna: Infraction_LTIS, Score ANOVA: 178.13986289720387\n",
      "Columna: Infraction_PTY, Score ANOVA: 159.86577366423217\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 133.7080164277688\n",
      "Columna: Infraction_JYZB, Score ANOVA: 118.01530658375242\n",
      "Columna: Base_4569, Score ANOVA: 72.14844848903044\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 65.98088013906921\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 48.93900491222959\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 34.16026177391408\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 22.922034872782593\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 7.2706815345395555\n",
      "Columna: ID, Score ANOVA: 6.480491533025721\n",
      "Columna: Infraction_IBJ, Score ANOVA: 5.4823602007245755\n",
      "Columna: Base_0580, Score ANOVA: 0.4238850169844678\n",
      "Columna: Base_7331, Score ANOVA: 0.35967314121461663\n",
      "Columna: Risk_3506, Score ANOVA: 0.23792326667132493\n",
      "\n",
      "\n",
      "Partición 3:\n",
      "Columna: Payment_6804, Score ANOVA: 287056.08417614346\n",
      "Columna: Base_69608, Score ANOVA: 155332.08612846548\n",
      "Columna: Base_80863, Score ANOVA: 148801.97116092753\n",
      "Columna: Base_85131, Score ANOVA: 138996.58673887214\n",
      "Columna: Infraction_CZE, Score ANOVA: 129933.70061714253\n",
      "Columna: Infraction_QJJF, Score ANOVA: 128842.45097011728\n",
      "Columna: Infraction_BSU, Score ANOVA: 127460.20749228954\n",
      "Columna: Base_9103, Score ANOVA: 127054.54748915165\n",
      "Columna: Infraction_ZYW, Score ANOVA: 126011.58296211131\n",
      "Columna: Base_39598, Score ANOVA: 113706.48541547092\n",
      "Columna: Base_67254_encoded, Score ANOVA: 112570.1744161398\n",
      "Columna: Base_02683, Score ANOVA: 112533.80404058246\n",
      "Columna: Base_3041, Score ANOVA: 108939.99133456365\n",
      "Columna: Infraction_QKZN, Score ANOVA: 106128.16132994495\n",
      "Columna: Base_76065, Score ANOVA: 100087.70786253478\n",
      "Columna: Base_0229, Score ANOVA: 92118.40757696923\n",
      "Columna: Base_91828, Score ANOVA: 89594.3087001337\n",
      "Columna: Base_7744, Score ANOVA: 88390.24170335584\n",
      "Columna: Base_2810, Score ANOVA: 86921.58478858037\n",
      "Columna: Base_6852, Score ANOVA: 85103.49092715338\n",
      "Columna: Base_36384, Score ANOVA: 77997.99670323092\n",
      "Columna: Base_22178, Score ANOVA: 77967.9611452157\n",
      "Columna: Risk_1930, Score ANOVA: 75722.88756473297\n",
      "Columna: Base_8730, Score ANOVA: 70413.62262403307\n",
      "Columna: Base_6187, Score ANOVA: 55914.024662601834\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 49504.19131538569\n",
      "Columna: Risk_9995, Score ANOVA: 44995.6246379583\n",
      "Columna: Infraction_GGO, Score ANOVA: 40463.15161177205\n",
      "Columna: Risk_8902, Score ANOVA: 39465.56124097236\n",
      "Columna: Infraction_EJZ, Score ANOVA: 38195.838718707244\n",
      "Columna: Risk_0322, Score ANOVA: 36938.1980456759\n",
      "Columna: Infraction_RXQH, Score ANOVA: 36886.5302132577\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 34408.26962868048\n",
      "Columna: Infraction_SNZ, Score ANOVA: 31470.711923674928\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 31455.083663708934\n",
      "Columna: Payment_22507, Score ANOVA: 30093.07718193361\n",
      "Columna: Risk_2102, Score ANOVA: 29482.880212619086\n",
      "Columna: Base_67585, Score ANOVA: 28580.088056100863\n",
      "Columna: Payment_3207, Score ANOVA: 28546.957651652814\n",
      "Columna: Infraction_VHHP, Score ANOVA: 28058.529769499397\n",
      "Columna: Risk_0003, Score ANOVA: 24983.336896834604\n",
      "Columna: Infraction_HFU, Score ANOVA: 24808.49529944788\n",
      "Columna: Infraction_AYWV, Score ANOVA: 24770.715378283694\n",
      "Columna: Infraction_BGGU, Score ANOVA: 24347.730193066232\n",
      "Columna: Infraction_HUK, Score ANOVA: 21940.313216133516\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 18960.217722097448\n",
      "Columna: Infraction_HSSU, Score ANOVA: 18836.364546013512\n",
      "Columna: Infraction_GSS, Score ANOVA: 18400.070194850836\n",
      "Columna: Infraction_WIS, Score ANOVA: 18198.121634198687\n",
      "Columna: Infraction_CGP, Score ANOVA: 17389.562592722992\n",
      "Columna: Base_66195, Score ANOVA: 17353.961791021156\n",
      "Columna: Infraction_CZXL, Score ANOVA: 17102.712702469365\n",
      "Columna: Infraction_EYU, Score ANOVA: 16599.15406417152\n",
      "Columna: Infraction_SIA, Score ANOVA: 16497.646786837417\n",
      "Columna: Infraction_NMCB, Score ANOVA: 16469.733703806065\n",
      "Columna: Infraction_TPAF, Score ANOVA: 15561.617717556941\n",
      "Columna: Infraction_XWX, Score ANOVA: 15300.300364705492\n",
      "Columna: Risk_8065, Score ANOVA: 14205.327449906003\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 14158.282737874415\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 13976.39467001271\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 13836.064189599545\n",
      "Columna: Infraction_RKTA, Score ANOVA: 12696.375078617099\n",
      "Columna: Risk_6346, Score ANOVA: 11934.316169983313\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 11933.615995940774\n",
      "Columna: Risk_8532, Score ANOVA: 11798.736637290549\n",
      "Columna: Infraction_LMHK, Score ANOVA: 11529.717524417905\n",
      "Columna: Infraction_IIZ, Score ANOVA: 11446.35842788939\n",
      "Columna: Infraction_WVC, Score ANOVA: 11407.66406808618\n",
      "Columna: Risk_6977, Score ANOVA: 11288.229080521136\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 10728.170989734563\n",
      "Columna: Infraction_LIES, Score ANOVA: 9578.372747783867\n",
      "Columna: Risk_2380, Score ANOVA: 8768.545754414867\n",
      "Columna: Infraction_QEY, Score ANOVA: 8667.777304816633\n",
      "Columna: Infraction_PAS, Score ANOVA: 8628.555454423335\n",
      "Columna: Risk_0454, Score ANOVA: 8596.379379237906\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 8565.347535119852\n",
      "Columna: Expenditure_GMC, Score ANOVA: 7890.10150835355\n",
      "Columna: Risk_4553, Score ANOVA: 7856.462910464514\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 7589.445088167967\n",
      "Columna: Infraction_YQXM, Score ANOVA: 6945.275283924807\n",
      "Columna: Infraction_HFSI, Score ANOVA: 6942.25546081909\n",
      "Columna: Infraction_ETH, Score ANOVA: 6835.726813273715\n",
      "Columna: Infraction_LSX, Score ANOVA: 6777.598700830686\n",
      "Columna: Infraction_QWWW, Score ANOVA: 6758.1410487046505\n",
      "Columna: Infraction_SDWM, Score ANOVA: 6553.526324253879\n",
      "Columna: Risk_9423, Score ANOVA: 6515.929178621985\n",
      "Columna: Infraction_QGR, Score ANOVA: 6426.545569470816\n",
      "Columna: Infraction_KSBR, Score ANOVA: 5969.28916807558\n",
      "Columna: Infraction_DNOU, Score ANOVA: 5543.2297119426075\n",
      "Columna: Risk_9367, Score ANOVA: 5514.502901250278\n",
      "Columna: Risk_1475, Score ANOVA: 5493.547118056079\n",
      "Columna: Expenditure_BWX, Score ANOVA: 5384.193351030336\n",
      "Columna: Base_65352, Score ANOVA: 5283.965900860277\n",
      "Columna: Expenditure_FIP, Score ANOVA: 5204.611686590662\n",
      "Columna: Base_7910, Score ANOVA: 5096.18864689417\n",
      "Columna: Risk_8742, Score ANOVA: 4984.118183455028\n",
      "Columna: Risk_4804, Score ANOVA: 4739.93563471267\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 4224.080325950824\n",
      "Columna: Infraction_AQO, Score ANOVA: 4037.2784600276836\n",
      "Columna: Base_1039, Score ANOVA: 3989.8693544634693\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 3971.4358753146325\n",
      "Columna: Base_52892, Score ANOVA: 3795.0228760906352\n",
      "Columna: Expenditure_RGD, Score ANOVA: 3555.7504449554194\n",
      "Columna: Base_8511, Score ANOVA: 3433.551312116079\n",
      "Columna: Infraction_VHU, Score ANOVA: 3305.2730444126055\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 3092.09311138778\n",
      "Columna: Risk_4160, Score ANOVA: 2872.700509709338\n",
      "Columna: Infraction_EHZP, Score ANOVA: 2828.761102612026\n",
      "Columna: Base_1165, Score ANOVA: 2703.3194552085242\n",
      "Columna: Infraction_TFOY, Score ANOVA: 2552.577482233478\n",
      "Columna: Infraction_ZVW, Score ANOVA: 2500.4269156903683\n",
      "Columna: Infraction_WVAW, Score ANOVA: 2342.1051370818827\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 2185.444890292906\n",
      "Columna: Infraction_QXUM, Score ANOVA: 2184.8723999559184\n",
      "Columna: Infraction_MHM, Score ANOVA: 2164.255563814147\n",
      "Columna: Risk_7095, Score ANOVA: 2035.6512737134763\n",
      "Columna: Risk_6178, Score ANOVA: 1913.8258649132788\n",
      "Columna: Infraction_IMIM, Score ANOVA: 1849.2364371242193\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 1791.3400263828028\n",
      "Columna: Risk_9247, Score ANOVA: 1767.593199495377\n",
      "Columna: Base_23737, Score ANOVA: 1728.2732533652056\n",
      "Columna: Expenditure_YTR, Score ANOVA: 1662.1399098367701\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1661.180971153688\n",
      "Columna: Infraction_VTR, Score ANOVA: 1535.7959852055608\n",
      "Columna: Base_6872, Score ANOVA: 1504.2323623053867\n",
      "Columna: Base_24406, Score ANOVA: 1171.4652188228556\n",
      "Columna: Risk_4247, Score ANOVA: 1013.1664830733329\n",
      "Columna: Base_5441, Score ANOVA: 941.799860098593\n",
      "Columna: Risk_5270, Score ANOVA: 693.0492214183286\n",
      "Columna: Base_14808, Score ANOVA: 670.0471633646288\n",
      "Columna: Expenditure_HPM, Score ANOVA: 600.2816493402971\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 586.7727109103868\n",
      "Columna: Infraction_QVSL, Score ANOVA: 562.5661715322094\n",
      "Columna: Expenditure_XDD, Score ANOVA: 489.3575170304768\n",
      "Columna: Infraction_ZRH, Score ANOVA: 443.99346249342346\n",
      "Columna: Infraction_PTY, Score ANOVA: 281.3983281883945\n",
      "Columna: Base_36516, Score ANOVA: 245.79009837844765\n",
      "Columna: Base_9516, Score ANOVA: 174.2119842145745\n",
      "Columna: Base_4569, Score ANOVA: 109.10932292973673\n",
      "Columna: Infraction_JYZB, Score ANOVA: 88.3282371018986\n",
      "Columna: Infraction_LTIS, Score ANOVA: 84.43721480840127\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 80.93471779577214\n",
      "Columna: Infraction_IBJ, Score ANOVA: 76.3506395829238\n",
      "Columna: Base_0580, Score ANOVA: 70.5489444104521\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 67.96428419245103\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 65.06783682659362\n",
      "Columna: Risk_6197, Score ANOVA: 53.67691706826741\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 41.29455639859575\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 38.00323274520782\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 4.548753916965191\n",
      "Columna: Risk_3506, Score ANOVA: 3.313336831283297\n",
      "Columna: ID, Score ANOVA: 0.28238895017860105\n",
      "Columna: Base_7331, Score ANOVA: 0.14502574437551954\n",
      "\n",
      "\n",
      "Partición 4:\n",
      "Columna: Payment_6804, Score ANOVA: 288438.65785434813\n",
      "Columna: Base_69608, Score ANOVA: 153917.39160595942\n",
      "Columna: Base_80863, Score ANOVA: 151461.3597393891\n",
      "Columna: Base_85131, Score ANOVA: 148984.42487563635\n",
      "Columna: Infraction_CZE, Score ANOVA: 129322.00400424271\n",
      "Columna: Infraction_QJJF, Score ANOVA: 127728.18671381372\n",
      "Columna: Base_9103, Score ANOVA: 127721.69032025449\n",
      "Columna: Infraction_BSU, Score ANOVA: 127626.15126125752\n",
      "Columna: Infraction_ZYW, Score ANOVA: 123052.09223221497\n",
      "Columna: Base_39598, Score ANOVA: 115417.91127040642\n",
      "Columna: Base_02683, Score ANOVA: 113522.26291091225\n",
      "Columna: Base_67254_encoded, Score ANOVA: 110889.81221700732\n",
      "Columna: Base_3041, Score ANOVA: 110295.99707802183\n",
      "Columna: Infraction_QKZN, Score ANOVA: 104220.352370093\n",
      "Columna: Base_76065, Score ANOVA: 96863.53685172858\n",
      "Columna: Base_0229, Score ANOVA: 92515.40126422186\n",
      "Columna: Base_7744, Score ANOVA: 88358.25800069788\n",
      "Columna: Base_2810, Score ANOVA: 87046.72266945723\n",
      "Columna: Base_91828, Score ANOVA: 86810.26582692863\n",
      "Columna: Base_6852, Score ANOVA: 86610.14427337438\n",
      "Columna: Base_22178, Score ANOVA: 78067.09937994997\n",
      "Columna: Base_36384, Score ANOVA: 77517.80811247979\n",
      "Columna: Risk_1930, Score ANOVA: 74222.46689443143\n",
      "Columna: Base_8730, Score ANOVA: 68343.54277095392\n",
      "Columna: Base_6187, Score ANOVA: 56921.08639582575\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 47166.22143604491\n",
      "Columna: Risk_9995, Score ANOVA: 44973.385998998165\n",
      "Columna: Infraction_GGO, Score ANOVA: 42967.09710940244\n",
      "Columna: Risk_8902, Score ANOVA: 40412.52115326296\n",
      "Columna: Infraction_EJZ, Score ANOVA: 39242.830797587965\n",
      "Columna: Risk_0322, Score ANOVA: 37305.24819625325\n",
      "Columna: Infraction_RXQH, Score ANOVA: 35752.424462230614\n",
      "Columna: Infraction_SNZ, Score ANOVA: 33850.60439290157\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 32358.939410355408\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 31387.33710704896\n",
      "Columna: Base_67585, Score ANOVA: 28550.302558650324\n",
      "Columna: Payment_3207, Score ANOVA: 28231.989954156015\n",
      "Columna: Payment_22507, Score ANOVA: 28091.80047231668\n",
      "Columna: Risk_2102, Score ANOVA: 27967.36283597787\n",
      "Columna: Infraction_VHHP, Score ANOVA: 27581.068282410244\n",
      "Columna: Infraction_BGGU, Score ANOVA: 26119.531299716364\n",
      "Columna: Infraction_AYWV, Score ANOVA: 25994.765367419783\n",
      "Columna: Risk_0003, Score ANOVA: 25630.602873867403\n",
      "Columna: Infraction_HFU, Score ANOVA: 24518.499475559885\n",
      "Columna: Infraction_HUK, Score ANOVA: 22787.461644535095\n",
      "Columna: Infraction_HSSU, Score ANOVA: 20187.902328978387\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 19358.700864994535\n",
      "Columna: Infraction_GSS, Score ANOVA: 18785.045905012208\n",
      "Columna: Infraction_WIS, Score ANOVA: 17966.551302985197\n",
      "Columna: Base_66195, Score ANOVA: 17472.542927774444\n",
      "Columna: Infraction_SIA, Score ANOVA: 16717.59318192194\n",
      "Columna: Infraction_CGP, Score ANOVA: 16653.081976033878\n",
      "Columna: Infraction_XWX, Score ANOVA: 16575.72006728362\n",
      "Columna: Infraction_TPAF, Score ANOVA: 16247.80163146602\n",
      "Columna: Infraction_NMCB, Score ANOVA: 15981.115099433942\n",
      "Columna: Infraction_EYU, Score ANOVA: 15763.212066976785\n",
      "Columna: Infraction_CZXL, Score ANOVA: 15529.961497530752\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 14790.286781243745\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 14528.510652575918\n",
      "Columna: Risk_8065, Score ANOVA: 14470.80668082357\n",
      "Columna: Infraction_RKTA, Score ANOVA: 13932.478776037407\n",
      "Columna: Infraction_IIZ, Score ANOVA: 12781.647983199673\n",
      "Columna: Infraction_LMHK, Score ANOVA: 12669.90262558574\n",
      "Columna: Risk_6346, Score ANOVA: 12464.24388409673\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 11733.224256570533\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 11571.456764822735\n",
      "Columna: Risk_6977, Score ANOVA: 11406.796526497581\n",
      "Columna: Risk_8532, Score ANOVA: 11038.770483504868\n",
      "Columna: Infraction_WVC, Score ANOVA: 10895.604559320385\n",
      "Columna: Infraction_PAS, Score ANOVA: 10099.477999394385\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 10047.54261849697\n",
      "Columna: Infraction_LIES, Score ANOVA: 9863.466670015534\n",
      "Columna: Risk_4553, Score ANOVA: 9783.169464319017\n",
      "Columna: Expenditure_GMC, Score ANOVA: 8822.536191378222\n",
      "Columna: Risk_0454, Score ANOVA: 8573.847125332532\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 8563.908733848211\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 8536.17048361693\n",
      "Columna: Risk_2380, Score ANOVA: 8379.46473953531\n",
      "Columna: Infraction_QEY, Score ANOVA: 7570.692096565509\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 7268.16865401757\n",
      "Columna: Infraction_SDWM, Score ANOVA: 7098.207293419457\n",
      "Columna: Infraction_HFSI, Score ANOVA: 6957.967552367913\n",
      "Columna: Infraction_ETH, Score ANOVA: 6876.135144031941\n",
      "Columna: Infraction_QWWW, Score ANOVA: 6689.142019522036\n",
      "Columna: Infraction_LSX, Score ANOVA: 6671.609317048565\n",
      "Columna: Base_65352, Score ANOVA: 6527.072753636277\n",
      "Columna: Infraction_QGR, Score ANOVA: 6390.735205717157\n",
      "Columna: Infraction_KSBR, Score ANOVA: 6193.576982865639\n",
      "Columna: Infraction_DNOU, Score ANOVA: 5977.480023025141\n",
      "Columna: Infraction_YQXM, Score ANOVA: 5956.055730789517\n",
      "Columna: Risk_9423, Score ANOVA: 5898.775338608588\n",
      "Columna: Risk_1475, Score ANOVA: 5871.265500513778\n",
      "Columna: Expenditure_BWX, Score ANOVA: 5267.138087970454\n",
      "Columna: Expenditure_FIP, Score ANOVA: 5237.323582939782\n",
      "Columna: Risk_8742, Score ANOVA: 4947.540529990006\n",
      "Columna: Base_1039, Score ANOVA: 4832.717300826443\n",
      "Columna: Risk_9367, Score ANOVA: 4745.849138846271\n",
      "Columna: Base_7910, Score ANOVA: 4631.776652899272\n",
      "Columna: Risk_4804, Score ANOVA: 4631.775391146856\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 4415.171356371054\n",
      "Columna: Base_8511, Score ANOVA: 4012.242910736734\n",
      "Columna: Base_52892, Score ANOVA: 3945.7692939564604\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 3888.6848022942204\n",
      "Columna: Infraction_ZVW, Score ANOVA: 3585.883318200854\n",
      "Columna: Infraction_VHU, Score ANOVA: 3503.4857543202506\n",
      "Columna: Expenditure_RGD, Score ANOVA: 3032.2567411278123\n",
      "Columna: Base_6872, Score ANOVA: 2893.686669806618\n",
      "Columna: Base_4569, Score ANOVA: 2796.386550101331\n",
      "Columna: Risk_4160, Score ANOVA: 2759.537610094078\n",
      "Columna: Infraction_AQO, Score ANOVA: 2446.835525916815\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 2442.836132278177\n",
      "Columna: Risk_7095, Score ANOVA: 2399.8951920276286\n",
      "Columna: Base_1165, Score ANOVA: 2359.1045509027813\n",
      "Columna: Infraction_EHZP, Score ANOVA: 2323.160449527035\n",
      "Columna: Infraction_TFOY, Score ANOVA: 2258.238096620634\n",
      "Columna: Infraction_QXUM, Score ANOVA: 2250.7171132618237\n",
      "Columna: Infraction_MHM, Score ANOVA: 2188.2162031760618\n",
      "Columna: Risk_9247, Score ANOVA: 2187.1441573587326\n",
      "Columna: Risk_6178, Score ANOVA: 2137.2507785977227\n",
      "Columna: Base_23737, Score ANOVA: 2119.791225329709\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 2024.0607297817967\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1731.7940141971403\n",
      "Columna: Infraction_IMIM, Score ANOVA: 1680.76768235725\n",
      "Columna: Infraction_VTR, Score ANOVA: 1475.7561938099777\n",
      "Columna: Base_24406, Score ANOVA: 1390.1487124407436\n",
      "Columna: Expenditure_HPM, Score ANOVA: 1219.7084541168063\n",
      "Columna: Base_14808, Score ANOVA: 843.8052199088482\n",
      "Columna: Expenditure_YTR, Score ANOVA: 817.3126252226954\n",
      "Columna: Base_5441, Score ANOVA: 755.267589549731\n",
      "Columna: Infraction_ZRH, Score ANOVA: 486.0296264824177\n",
      "Columna: Risk_4247, Score ANOVA: 437.8441512362745\n",
      "Columna: Expenditure_XDD, Score ANOVA: 436.7317701166275\n",
      "Columna: Infraction_QVSL, Score ANOVA: 429.53904682101034\n",
      "Columna: Infraction_WVAW, Score ANOVA: 420.92936074141573\n",
      "Columna: Base_9516, Score ANOVA: 389.3772648403118\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 388.47921957268255\n",
      "Columna: Base_36516, Score ANOVA: 346.21132816401104\n",
      "Columna: Risk_5270, Score ANOVA: 235.3557854966813\n",
      "Columna: Infraction_PTY, Score ANOVA: 181.05182692505898\n",
      "Columna: Infraction_JYZB, Score ANOVA: 154.38795324493023\n",
      "Columna: Infraction_LTIS, Score ANOVA: 119.50099413635488\n",
      "Columna: Base_0580, Score ANOVA: 89.88890015508946\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 75.7765687580203\n",
      "Columna: Risk_6197, Score ANOVA: 72.4597493403684\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 54.79754174740456\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 41.80832334143759\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 29.556556410512453\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 22.52149199757476\n",
      "Columna: Infraction_IBJ, Score ANOVA: 14.556624294353677\n",
      "Columna: Base_7331, Score ANOVA: 13.799984922461885\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 4.884543332024276\n",
      "Columna: ID, Score ANOVA: 3.5814773108974354\n",
      "Columna: Risk_3506, Score ANOVA: 1.7398331265620701\n",
      "\n",
      "\n",
      "Partición 5:\n",
      "Columna: Payment_6804, Score ANOVA: 288940.6194596243\n",
      "Columna: Base_69608, Score ANOVA: 158965.7617669868\n",
      "Columna: Base_80863, Score ANOVA: 156621.50703951172\n",
      "Columna: Base_85131, Score ANOVA: 145319.33260305028\n",
      "Columna: Infraction_CZE, Score ANOVA: 132486.3178194132\n",
      "Columna: Base_9103, Score ANOVA: 131906.0715542395\n",
      "Columna: Infraction_QJJF, Score ANOVA: 131902.32864975242\n",
      "Columna: Infraction_ZYW, Score ANOVA: 126488.71635941337\n",
      "Columna: Infraction_BSU, Score ANOVA: 124870.25821727549\n",
      "Columna: Base_67254_encoded, Score ANOVA: 116750.31125673182\n",
      "Columna: Base_02683, Score ANOVA: 116010.31819121452\n",
      "Columna: Base_39598, Score ANOVA: 115691.6794254639\n",
      "Columna: Base_3041, Score ANOVA: 110481.35252678744\n",
      "Columna: Infraction_QKZN, Score ANOVA: 106978.80284532603\n",
      "Columna: Base_0229, Score ANOVA: 97387.96732950007\n",
      "Columna: Base_76065, Score ANOVA: 96716.28974753377\n",
      "Columna: Base_91828, Score ANOVA: 91513.04536010188\n",
      "Columna: Base_7744, Score ANOVA: 91092.88731785161\n",
      "Columna: Base_2810, Score ANOVA: 90217.47000042893\n",
      "Columna: Base_6852, Score ANOVA: 90198.76283970919\n",
      "Columna: Base_22178, Score ANOVA: 82200.28298792742\n",
      "Columna: Base_36384, Score ANOVA: 80150.27207399216\n",
      "Columna: Risk_1930, Score ANOVA: 74453.05752258419\n",
      "Columna: Base_8730, Score ANOVA: 72706.05961071703\n",
      "Columna: Base_6187, Score ANOVA: 53753.02902724584\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 49247.34858539596\n",
      "Columna: Risk_9995, Score ANOVA: 41117.676104244696\n",
      "Columna: Infraction_GGO, Score ANOVA: 40076.273071873344\n",
      "Columna: Risk_8902, Score ANOVA: 37313.98064240069\n",
      "Columna: Infraction_EJZ, Score ANOVA: 37312.56676820169\n",
      "Columna: Risk_0322, Score ANOVA: 36647.953609519194\n",
      "Columna: Infraction_RXQH, Score ANOVA: 36460.98516695111\n",
      "Columna: Infraction_SNZ, Score ANOVA: 33924.823178601626\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 32886.28287200064\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 31504.485495271587\n",
      "Columna: Payment_3207, Score ANOVA: 28911.27647436504\n",
      "Columna: Payment_22507, Score ANOVA: 28588.72967996941\n",
      "Columna: Risk_2102, Score ANOVA: 28121.87090161551\n",
      "Columna: Infraction_VHHP, Score ANOVA: 27246.877622115226\n",
      "Columna: Base_67585, Score ANOVA: 26056.551953823946\n",
      "Columna: Infraction_BGGU, Score ANOVA: 25898.993590191716\n",
      "Columna: Infraction_AYWV, Score ANOVA: 25395.761974335488\n",
      "Columna: Infraction_HFU, Score ANOVA: 25179.716281890403\n",
      "Columna: Risk_0003, Score ANOVA: 24856.014752454696\n",
      "Columna: Infraction_HUK, Score ANOVA: 24084.57263973132\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 19329.02854293517\n",
      "Columna: Infraction_HSSU, Score ANOVA: 18541.465216190765\n",
      "Columna: Base_66195, Score ANOVA: 18481.782823668247\n",
      "Columna: Infraction_WIS, Score ANOVA: 17984.562689467588\n",
      "Columna: Infraction_GSS, Score ANOVA: 17922.47024705448\n",
      "Columna: Infraction_NMCB, Score ANOVA: 16852.237393798845\n",
      "Columna: Infraction_SIA, Score ANOVA: 16511.716576611598\n",
      "Columna: Infraction_XWX, Score ANOVA: 16477.042366823647\n",
      "Columna: Infraction_CGP, Score ANOVA: 16230.022858020993\n",
      "Columna: Infraction_EYU, Score ANOVA: 16119.570148117971\n",
      "Columna: Infraction_CZXL, Score ANOVA: 15708.938341776366\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 15382.987341627813\n",
      "Columna: Infraction_TPAF, Score ANOVA: 14341.403626151221\n",
      "Columna: Risk_8065, Score ANOVA: 14144.646484473546\n",
      "Columna: Infraction_RKTA, Score ANOVA: 13762.301319954682\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 12783.02088911724\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 12725.601389784884\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 12433.958820119118\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 12416.622430625832\n",
      "Columna: Risk_6977, Score ANOVA: 11822.54808431537\n",
      "Columna: Risk_6346, Score ANOVA: 11751.635871265342\n",
      "Columna: Infraction_LMHK, Score ANOVA: 11598.800800413388\n",
      "Columna: Infraction_WVC, Score ANOVA: 11418.210647869146\n",
      "Columna: Risk_8532, Score ANOVA: 11130.732391557673\n",
      "Columna: Infraction_IIZ, Score ANOVA: 10772.910437353823\n",
      "Columna: Infraction_PAS, Score ANOVA: 10055.12600304343\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 9736.145691862412\n",
      "Columna: Expenditure_GMC, Score ANOVA: 8867.650231663196\n",
      "Columna: Infraction_LIES, Score ANOVA: 8864.447657314933\n",
      "Columna: Risk_4553, Score ANOVA: 8681.86248901174\n",
      "Columna: Risk_2380, Score ANOVA: 8376.080098517583\n",
      "Columna: Risk_0454, Score ANOVA: 8167.170728513462\n",
      "Columna: Infraction_QWWW, Score ANOVA: 8140.180370145397\n",
      "Columna: Infraction_LSX, Score ANOVA: 8127.679892497329\n",
      "Columna: Infraction_HFSI, Score ANOVA: 8065.828377390803\n",
      "Columna: Infraction_ETH, Score ANOVA: 7968.275600855433\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 7938.256846066502\n",
      "Columna: Infraction_QEY, Score ANOVA: 7782.435591512519\n",
      "Columna: Infraction_QGR, Score ANOVA: 7755.965026390207\n",
      "Columna: Infraction_SDWM, Score ANOVA: 7729.327142018874\n",
      "Columna: Infraction_YQXM, Score ANOVA: 7188.554208582509\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 7088.383788264533\n",
      "Columna: Infraction_DNOU, Score ANOVA: 6431.568758209662\n",
      "Columna: Base_7910, Score ANOVA: 6217.682004236074\n",
      "Columna: Risk_9423, Score ANOVA: 6011.972968120164\n",
      "Columna: Expenditure_BWX, Score ANOVA: 5992.853137815565\n",
      "Columna: Infraction_KSBR, Score ANOVA: 5863.847930014517\n",
      "Columna: Base_65352, Score ANOVA: 5740.493683249598\n",
      "Columna: Risk_1475, Score ANOVA: 5583.508722925007\n",
      "Columna: Risk_8742, Score ANOVA: 4783.40976601783\n",
      "Columna: Base_8511, Score ANOVA: 4751.642216609993\n",
      "Columna: Risk_9367, Score ANOVA: 4525.891597038256\n",
      "Columna: Risk_4804, Score ANOVA: 4508.717178441788\n",
      "Columna: Base_52892, Score ANOVA: 4495.842449608011\n",
      "Columna: Expenditure_FIP, Score ANOVA: 4486.546416260597\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 4190.557600595688\n",
      "Columna: Infraction_AQO, Score ANOVA: 4007.0454948140828\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 3954.246602572776\n",
      "Columna: Infraction_ZVW, Score ANOVA: 3867.6894383832323\n",
      "Columna: Expenditure_RGD, Score ANOVA: 3834.7134359631523\n",
      "Columna: Infraction_EHZP, Score ANOVA: 3141.206427981966\n",
      "Columna: Infraction_VHU, Score ANOVA: 3112.3886285269164\n",
      "Columna: Base_1039, Score ANOVA: 2955.908761512876\n",
      "Columna: Infraction_TFOY, Score ANOVA: 2803.1344098281716\n",
      "Columna: Base_6872, Score ANOVA: 2677.627494978746\n",
      "Columna: Risk_4160, Score ANOVA: 2641.2429176923183\n",
      "Columna: Infraction_VTR, Score ANOVA: 2475.5030326044243\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 2445.62281331774\n",
      "Columna: Infraction_WVAW, Score ANOVA: 2439.3664066188817\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 2313.7725356919245\n",
      "Columna: Infraction_QXUM, Score ANOVA: 2218.33813674992\n",
      "Columna: Infraction_MHM, Score ANOVA: 2195.5691570200515\n",
      "Columna: Risk_6178, Score ANOVA: 1961.5926762803579\n",
      "Columna: Expenditure_HPM, Score ANOVA: 1914.7351529927487\n",
      "Columna: Base_1165, Score ANOVA: 1887.3527230855632\n",
      "Columna: Risk_9247, Score ANOVA: 1789.2440302660027\n",
      "Columna: Risk_7095, Score ANOVA: 1704.3925026111826\n",
      "Columna: Base_23737, Score ANOVA: 1686.4514950768373\n",
      "Columna: Infraction_IMIM, Score ANOVA: 1685.308651168126\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1164.177348985647\n",
      "Columna: Base_5441, Score ANOVA: 835.988668897468\n",
      "Columna: Expenditure_YTR, Score ANOVA: 802.743021327538\n",
      "Columna: Base_24406, Score ANOVA: 792.436776660872\n",
      "Columna: Base_4569, Score ANOVA: 732.4468031067942\n",
      "Columna: Infraction_QVSL, Score ANOVA: 697.1111766916099\n",
      "Columna: Risk_4247, Score ANOVA: 660.3857586877202\n",
      "Columna: Base_14808, Score ANOVA: 609.2305870868101\n",
      "Columna: Expenditure_XDD, Score ANOVA: 582.3786167236206\n",
      "Columna: Base_9516, Score ANOVA: 455.89165800968124\n",
      "Columna: Risk_5270, Score ANOVA: 451.9264098809127\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 401.1897043294935\n",
      "Columna: Infraction_JYZB, Score ANOVA: 313.151343586149\n",
      "Columna: Infraction_ZRH, Score ANOVA: 272.93913969267595\n",
      "Columna: Infraction_PTY, Score ANOVA: 245.7027587140032\n",
      "Columna: Infraction_LTIS, Score ANOVA: 235.58127198906246\n",
      "Columna: Risk_6197, Score ANOVA: 208.98962777207603\n",
      "Columna: Base_36516, Score ANOVA: 173.70327497914045\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 82.32866700562785\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 72.97768326726215\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 62.50602971884\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 58.017271663432446\n",
      "Columna: Infraction_IBJ, Score ANOVA: 39.24598347875288\n",
      "Columna: ID, Score ANOVA: 19.4200596758796\n",
      "Columna: Base_0580, Score ANOVA: 14.921282876099085\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 11.706975545103939\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 7.443034936064173\n",
      "Columna: Risk_3506, Score ANOVA: 2.472993096875867\n",
      "Columna: Base_7331, Score ANOVA: 0.9357634705839337\n",
      "\n",
      "\n",
      "Partición 6:\n",
      "Columna: Payment_6804, Score ANOVA: 299408.4219238525\n",
      "Columna: Base_69608, Score ANOVA: 159170.7486493599\n",
      "Columna: Base_85131, Score ANOVA: 158830.6987593244\n",
      "Columna: Base_80863, Score ANOVA: 157209.63908612446\n",
      "Columna: Infraction_QJJF, Score ANOVA: 139672.22465224063\n",
      "Columna: Infraction_CZE, Score ANOVA: 136658.39833225307\n",
      "Columna: Base_9103, Score ANOVA: 133866.59737351924\n",
      "Columna: Infraction_BSU, Score ANOVA: 129885.85596385472\n",
      "Columna: Infraction_ZYW, Score ANOVA: 127138.03630972066\n",
      "Columna: Base_02683, Score ANOVA: 116873.48753684529\n",
      "Columna: Base_39598, Score ANOVA: 114772.57982222155\n",
      "Columna: Base_67254_encoded, Score ANOVA: 113977.32491829575\n",
      "Columna: Infraction_QKZN, Score ANOVA: 110875.35481219404\n",
      "Columna: Base_3041, Score ANOVA: 109815.28639034875\n",
      "Columna: Base_76065, Score ANOVA: 97525.89887286663\n",
      "Columna: Base_0229, Score ANOVA: 95710.29718991074\n",
      "Columna: Base_6852, Score ANOVA: 89240.22329468007\n",
      "Columna: Base_7744, Score ANOVA: 88941.03463715066\n",
      "Columna: Base_91828, Score ANOVA: 88021.47122712033\n",
      "Columna: Base_2810, Score ANOVA: 87946.51398065225\n",
      "Columna: Base_22178, Score ANOVA: 81286.22471585088\n",
      "Columna: Risk_1930, Score ANOVA: 79822.84719324605\n",
      "Columna: Base_36384, Score ANOVA: 78055.91346663701\n",
      "Columna: Base_8730, Score ANOVA: 71725.37853243091\n",
      "Columna: Base_6187, Score ANOVA: 57367.47626332469\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 51948.255296057694\n",
      "Columna: Risk_9995, Score ANOVA: 46529.992849538896\n",
      "Columna: Infraction_GGO, Score ANOVA: 43298.017424377336\n",
      "Columna: Risk_8902, Score ANOVA: 39571.57741363119\n",
      "Columna: Infraction_EJZ, Score ANOVA: 38788.26678892869\n",
      "Columna: Risk_0322, Score ANOVA: 38520.47589730178\n",
      "Columna: Infraction_RXQH, Score ANOVA: 37834.32972906058\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 33170.5905629798\n",
      "Columna: Infraction_SNZ, Score ANOVA: 32372.578514413624\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 31913.67200930772\n",
      "Columna: Risk_2102, Score ANOVA: 29823.409715533744\n",
      "Columna: Payment_3207, Score ANOVA: 29573.332277977886\n",
      "Columna: Payment_22507, Score ANOVA: 29007.151605402883\n",
      "Columna: Infraction_VHHP, Score ANOVA: 28380.17605764403\n",
      "Columna: Base_67585, Score ANOVA: 27421.510013411902\n",
      "Columna: Infraction_HFU, Score ANOVA: 27014.133321755795\n",
      "Columna: Infraction_AYWV, Score ANOVA: 26974.720550839258\n",
      "Columna: Risk_0003, Score ANOVA: 26100.841964130537\n",
      "Columna: Infraction_BGGU, Score ANOVA: 25329.519512315117\n",
      "Columna: Infraction_HUK, Score ANOVA: 22784.573625013032\n",
      "Columna: Infraction_GSS, Score ANOVA: 19152.496099059026\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 19087.853940895722\n",
      "Columna: Infraction_XWX, Score ANOVA: 19018.794542335967\n",
      "Columna: Infraction_EYU, Score ANOVA: 18890.980307427857\n",
      "Columna: Infraction_CZXL, Score ANOVA: 18523.625495071905\n",
      "Columna: Infraction_NMCB, Score ANOVA: 18377.585075916322\n",
      "Columna: Infraction_HSSU, Score ANOVA: 18372.092484599565\n",
      "Columna: Base_66195, Score ANOVA: 18090.789460773838\n",
      "Columna: Infraction_WIS, Score ANOVA: 18030.268185176756\n",
      "Columna: Infraction_CGP, Score ANOVA: 17298.133929808148\n",
      "Columna: Infraction_SIA, Score ANOVA: 16852.772916360682\n",
      "Columna: Infraction_TPAF, Score ANOVA: 15045.283214687006\n",
      "Columna: Infraction_RKTA, Score ANOVA: 14573.302718821273\n",
      "Columna: Risk_8065, Score ANOVA: 14493.54514929426\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 14043.766405191389\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 14023.194282937424\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 13764.139279237344\n",
      "Columna: Risk_6977, Score ANOVA: 13690.280407694907\n",
      "Columna: Infraction_LMHK, Score ANOVA: 12858.166128625946\n",
      "Columna: Risk_6346, Score ANOVA: 12554.674820313885\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 12396.780382206687\n",
      "Columna: Infraction_IIZ, Score ANOVA: 12368.978905551954\n",
      "Columna: Risk_8532, Score ANOVA: 12073.42179067233\n",
      "Columna: Infraction_WVC, Score ANOVA: 11222.76645774991\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 10945.402723557276\n",
      "Columna: Risk_4553, Score ANOVA: 10888.426307184294\n",
      "Columna: Infraction_PAS, Score ANOVA: 10546.778834018558\n",
      "Columna: Expenditure_GMC, Score ANOVA: 10367.094398909821\n",
      "Columna: Infraction_LIES, Score ANOVA: 10063.891744037765\n",
      "Columna: Infraction_QEY, Score ANOVA: 9502.722988100897\n",
      "Columna: Infraction_LSX, Score ANOVA: 8771.367247694941\n",
      "Columna: Infraction_QWWW, Score ANOVA: 8770.311878994073\n",
      "Columna: Risk_2380, Score ANOVA: 8597.196126765504\n",
      "Columna: Risk_0454, Score ANOVA: 8423.540598450836\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 8398.819593204831\n",
      "Columna: Infraction_QGR, Score ANOVA: 8357.756616004723\n",
      "Columna: Infraction_YQXM, Score ANOVA: 7708.973417080116\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 7382.373026799142\n",
      "Columna: Infraction_DNOU, Score ANOVA: 7071.773075646053\n",
      "Columna: Infraction_HFSI, Score ANOVA: 7063.4677425983855\n",
      "Columna: Infraction_ETH, Score ANOVA: 6983.701374296114\n",
      "Columna: Infraction_SDWM, Score ANOVA: 6698.802147912632\n",
      "Columna: Infraction_KSBR, Score ANOVA: 6617.707572980082\n",
      "Columna: Risk_9423, Score ANOVA: 6538.8194413065\n",
      "Columna: Risk_1475, Score ANOVA: 6125.95863568111\n",
      "Columna: Base_65352, Score ANOVA: 6039.836343707316\n",
      "Columna: Expenditure_BWX, Score ANOVA: 5996.976254146054\n",
      "Columna: Risk_9367, Score ANOVA: 5824.068027368801\n",
      "Columna: Base_7910, Score ANOVA: 5727.578008066476\n",
      "Columna: Risk_8742, Score ANOVA: 5320.869416209392\n",
      "Columna: Expenditure_FIP, Score ANOVA: 5058.158453999413\n",
      "Columna: Base_52892, Score ANOVA: 5026.49190975775\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 4522.400906125657\n",
      "Columna: Risk_4804, Score ANOVA: 4412.244966809585\n",
      "Columna: Base_8511, Score ANOVA: 4196.407709994358\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 4154.245601196929\n",
      "Columna: Expenditure_RGD, Score ANOVA: 3686.0872404306956\n",
      "Columna: Base_1039, Score ANOVA: 3449.652227578003\n",
      "Columna: Infraction_ZVW, Score ANOVA: 3349.115737669042\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 3326.8047226041044\n",
      "Columna: Infraction_VHU, Score ANOVA: 3156.0256192016486\n",
      "Columna: Infraction_EHZP, Score ANOVA: 3076.3714372344402\n",
      "Columna: Infraction_AQO, Score ANOVA: 3001.6125004151168\n",
      "Columna: Infraction_TFOY, Score ANOVA: 2886.821857652326\n",
      "Columna: Risk_4160, Score ANOVA: 2874.388177395046\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 2871.306581498824\n",
      "Columna: Risk_7095, Score ANOVA: 2653.458956602018\n",
      "Columna: Infraction_WVAW, Score ANOVA: 2566.197409683686\n",
      "Columna: Infraction_QXUM, Score ANOVA: 2478.6833904836662\n",
      "Columna: Base_6872, Score ANOVA: 2417.693997712169\n",
      "Columna: Risk_9247, Score ANOVA: 2283.1716598920657\n",
      "Columna: Risk_6178, Score ANOVA: 2282.9085491576543\n",
      "Columna: Infraction_MHM, Score ANOVA: 2118.9051329236872\n",
      "Columna: Base_23737, Score ANOVA: 2112.9780115911294\n",
      "Columna: Infraction_IMIM, Score ANOVA: 1945.2976165570692\n",
      "Columna: Infraction_VTR, Score ANOVA: 1837.0747795653733\n",
      "Columna: Expenditure_HPM, Score ANOVA: 1410.6208743487919\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1403.343137375216\n",
      "Columna: Base_24406, Score ANOVA: 1323.0079037612084\n",
      "Columna: Expenditure_YTR, Score ANOVA: 1078.2352858127795\n",
      "Columna: Base_14808, Score ANOVA: 997.4519215788666\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 844.8552348309165\n",
      "Columna: Base_5441, Score ANOVA: 781.7707002524885\n",
      "Columna: Base_4569, Score ANOVA: 750.3574377647482\n",
      "Columna: Infraction_QVSL, Score ANOVA: 704.2420330862872\n",
      "Columna: Expenditure_XDD, Score ANOVA: 646.617861029357\n",
      "Columna: Risk_4247, Score ANOVA: 513.6239677241451\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 466.2662524259703\n",
      "Columna: Infraction_ZRH, Score ANOVA: 357.21093681651234\n",
      "Columna: Base_36516, Score ANOVA: 338.97969727325125\n",
      "Columna: Base_1165, Score ANOVA: 270.165567466182\n",
      "Columna: Infraction_PTY, Score ANOVA: 245.0180630136851\n",
      "Columna: Risk_5270, Score ANOVA: 212.05764078279532\n",
      "Columna: Base_9516, Score ANOVA: 193.74122967938825\n",
      "Columna: Infraction_LTIS, Score ANOVA: 142.29920340553653\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 81.86576596781406\n",
      "Columna: Infraction_JYZB, Score ANOVA: 75.82819981623405\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 75.36664135097863\n",
      "Columna: Risk_6197, Score ANOVA: 70.01470455070701\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 34.0340783508703\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 24.281704850310355\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 14.667621231131182\n",
      "Columna: Infraction_IBJ, Score ANOVA: 10.988614424232575\n",
      "Columna: ID, Score ANOVA: 7.574087169885296\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 3.6274818539260525\n",
      "Columna: Base_7331, Score ANOVA: 3.387064893390044\n",
      "Columna: Risk_3506, Score ANOVA: 1.0543928944566157\n",
      "Columna: Base_0580, Score ANOVA: 0.6345250291735173\n",
      "\n",
      "\n",
      "Partición 7:\n",
      "Columna: Payment_6804, Score ANOVA: 186277.74199492083\n",
      "Columna: Base_69608, Score ANOVA: 98498.05934036417\n",
      "Columna: Base_80863, Score ANOVA: 97695.74942319942\n",
      "Columna: Base_85131, Score ANOVA: 92415.46421174744\n",
      "Columna: Infraction_CZE, Score ANOVA: 83609.91865374702\n",
      "Columna: Infraction_QJJF, Score ANOVA: 83446.06088517637\n",
      "Columna: Base_9103, Score ANOVA: 82238.11628243058\n",
      "Columna: Infraction_ZYW, Score ANOVA: 79838.39712587239\n",
      "Columna: Infraction_BSU, Score ANOVA: 77824.7167572748\n",
      "Columna: Base_39598, Score ANOVA: 74211.11633045596\n",
      "Columna: Base_67254_encoded, Score ANOVA: 73389.3972559419\n",
      "Columna: Base_02683, Score ANOVA: 72423.45045819186\n",
      "Columna: Base_3041, Score ANOVA: 70786.89354782595\n",
      "Columna: Infraction_QKZN, Score ANOVA: 67730.90893367639\n",
      "Columna: Base_76065, Score ANOVA: 61320.23113459058\n",
      "Columna: Base_7744, Score ANOVA: 58541.52703586593\n",
      "Columna: Base_0229, Score ANOVA: 58160.069506769076\n",
      "Columna: Base_91828, Score ANOVA: 57413.250503910815\n",
      "Columna: Base_2810, Score ANOVA: 57410.87189991302\n",
      "Columna: Base_6852, Score ANOVA: 52782.35553973473\n",
      "Columna: Base_22178, Score ANOVA: 52172.21455143686\n",
      "Columna: Base_36384, Score ANOVA: 51687.34564776419\n",
      "Columna: Risk_1930, Score ANOVA: 48324.87606131944\n",
      "Columna: Base_8730, Score ANOVA: 45923.24428897321\n",
      "Columna: Base_6187, Score ANOVA: 38581.24223429784\n",
      "Columna: Infraction_ZTYG, Score ANOVA: 31726.481207422803\n",
      "Columna: Risk_9995, Score ANOVA: 27993.671685588542\n",
      "Columna: Infraction_GGO, Score ANOVA: 27029.0119257031\n",
      "Columna: Infraction_EJZ, Score ANOVA: 26278.376816253505\n",
      "Columna: Risk_8902, Score ANOVA: 24998.388531879973\n",
      "Columna: Infraction_RXQH, Score ANOVA: 23725.311995938526\n",
      "Columna: Risk_0322, Score ANOVA: 23506.995320747952\n",
      "Columna: Expenditure_LAHK, Score ANOVA: 20965.210203410603\n",
      "Columna: Infraction_ZTNC, Score ANOVA: 20887.638874506694\n",
      "Columna: Payment_3207, Score ANOVA: 19759.743460354068\n",
      "Columna: Risk_2102, Score ANOVA: 18164.458350835877\n",
      "Columna: Infraction_SNZ, Score ANOVA: 18103.074471803327\n",
      "Columna: Payment_22507, Score ANOVA: 18036.748608106936\n",
      "Columna: Infraction_VHHP, Score ANOVA: 17843.634202542456\n",
      "Columna: Base_67585, Score ANOVA: 17430.17822040541\n",
      "Columna: Infraction_AYWV, Score ANOVA: 17305.889547295123\n",
      "Columna: Infraction_HFU, Score ANOVA: 16810.7419313125\n",
      "Columna: Risk_0003, Score ANOVA: 16228.848654029045\n",
      "Columna: Infraction_BGGU, Score ANOVA: 14196.302584178526\n",
      "Columna: Infraction_HUK, Score ANOVA: 13817.88430440882\n",
      "Columna: Expenditure_UWVG, Score ANOVA: 12931.39695932058\n",
      "Columna: Infraction_CZXL, Score ANOVA: 12351.324148661273\n",
      "Columna: Infraction_HSSU, Score ANOVA: 12062.659157975062\n",
      "Columna: Infraction_WIS, Score ANOVA: 11904.446559748649\n",
      "Columna: Infraction_GSS, Score ANOVA: 11784.717015911085\n",
      "Columna: Infraction_EYU, Score ANOVA: 11741.22333579535\n",
      "Columna: Infraction_NMCB, Score ANOVA: 11243.883854455054\n",
      "Columna: Base_66195, Score ANOVA: 11136.309292983804\n",
      "Columna: Infraction_SIA, Score ANOVA: 10771.531965607439\n",
      "Columna: Infraction_TPAF, Score ANOVA: 10267.20551840192\n",
      "Columna: Infraction_CGP, Score ANOVA: 10121.659758912956\n",
      "Columna: Infraction_XWX, Score ANOVA: 9914.91646119119\n",
      "Columna: Infraction_XEPQ, Score ANOVA: 9499.476589737305\n",
      "Columna: Infraction_ZMKI, Score ANOVA: 9282.35017776889\n",
      "Columna: Risk_8065, Score ANOVA: 9152.198686638796\n",
      "Columna: Infraction_DQLY_encoded, Score ANOVA: 8944.819975590788\n",
      "Columna: Infraction_RKTA, Score ANOVA: 8460.054360641214\n",
      "Columna: Infraction_LMHK, Score ANOVA: 8221.925562894394\n",
      "Columna: Expenditure_LMSR, Score ANOVA: 8050.138902413062\n",
      "Columna: Risk_6346, Score ANOVA: 7846.548496369513\n",
      "Columna: Infraction_IIZ, Score ANOVA: 7747.0172641928075\n",
      "Columna: Risk_8532, Score ANOVA: 7710.195077359237\n",
      "Columna: Risk_6977, Score ANOVA: 7413.7643556981175\n",
      "Columna: Infraction_CLH_encoded, Score ANOVA: 6977.259383411413\n",
      "Columna: Infraction_WVC, Score ANOVA: 6857.257755753314\n",
      "Columna: Infraction_LIES, Score ANOVA: 6625.582919858803\n",
      "Columna: Expenditure_ONEG, Score ANOVA: 6586.992704257262\n",
      "Columna: Infraction_PAS, Score ANOVA: 6439.972748334247\n",
      "Columna: Infraction_QEY, Score ANOVA: 6083.207676197778\n",
      "Columna: Infraction_TEN_encoded, Score ANOVA: 5694.744554026581\n",
      "Columna: Risk_2380, Score ANOVA: 5682.924930828607\n",
      "Columna: Expenditure_GMC, Score ANOVA: 5385.830468080298\n",
      "Columna: Risk_0454, Score ANOVA: 5271.746299902847\n",
      "Columna: Infraction_HFSI, Score ANOVA: 5166.972693202822\n",
      "Columna: Infraction_ETH, Score ANOVA: 5115.856901348316\n",
      "Columna: Risk_4553, Score ANOVA: 4925.5623559094365\n",
      "Columna: Infraction_LSX, Score ANOVA: 4540.848092154066\n",
      "Columna: Infraction_QWWW, Score ANOVA: 4520.442352865015\n",
      "Columna: Infraction_NRBQ, Score ANOVA: 4479.154627412995\n",
      "Columna: Infraction_SDWM, Score ANOVA: 4346.264202547147\n",
      "Columna: Infraction_QGR, Score ANOVA: 4321.979584198502\n",
      "Columna: Risk_9423, Score ANOVA: 4286.344200170115\n",
      "Columna: Risk_1475, Score ANOVA: 3998.5583219713108\n",
      "Columna: Expenditure_BWX, Score ANOVA: 3864.796693676037\n",
      "Columna: Infraction_KSBR, Score ANOVA: 3802.9456634964504\n",
      "Columna: Base_65352, Score ANOVA: 3528.473150180195\n",
      "Columna: Risk_9367, Score ANOVA: 3411.5696927179315\n",
      "Columna: Infraction_DNOU, Score ANOVA: 3401.099458167348\n",
      "Columna: Infraction_YQXM, Score ANOVA: 3321.237722874009\n",
      "Columna: Risk_8742, Score ANOVA: 3273.099029797349\n",
      "Columna: Infraction_AQO, Score ANOVA: 3260.90183441823\n",
      "Columna: Base_7910, Score ANOVA: 3211.9737841637548\n",
      "Columna: Risk_4804, Score ANOVA: 3091.5406736691184\n",
      "Columna: Base_52892, Score ANOVA: 3015.9119783033866\n",
      "Columna: Expenditure_FIP, Score ANOVA: 2973.8185275339497\n",
      "Columna: Expenditure_MTRQ, Score ANOVA: 2887.327411134367\n",
      "Columna: Expenditure_RGD, Score ANOVA: 2640.4571472827233\n",
      "Columna: Base_1039, Score ANOVA: 2636.9384740921355\n",
      "Columna: Base_8511, Score ANOVA: 2621.1700311399773\n",
      "Columna: Infraction_ZVW, Score ANOVA: 2235.9144318035696\n",
      "Columna: Expenditure_UIWS, Score ANOVA: 2129.0267472142564\n",
      "Columna: Base_6872, Score ANOVA: 2067.7730919686096\n",
      "Columna: Expenditure_HRQ, Score ANOVA: 1903.1323519398818\n",
      "Columna: Infraction_EHZP, Score ANOVA: 1899.6460155544735\n",
      "Columna: Infraction_TFOY, Score ANOVA: 1765.1608829191985\n",
      "Columna: Infraction_YFSG_encoded, Score ANOVA: 1683.9031003251953\n",
      "Columna: Risk_4160, Score ANOVA: 1637.8804600085152\n",
      "Columna: Infraction_MHM, Score ANOVA: 1619.22497181855\n",
      "Columna: Risk_6178, Score ANOVA: 1530.570950129212\n",
      "Columna: Infraction_WVAW, Score ANOVA: 1513.9248242224958\n",
      "Columna: Infraction_QXUM, Score ANOVA: 1445.7139602479015\n",
      "Columna: Base_24406, Score ANOVA: 1343.4703244682833\n",
      "Columna: Infraction_VHU, Score ANOVA: 1335.5857744865484\n",
      "Columna: Base_4569, Score ANOVA: 1263.088090181611\n",
      "Columna: Infraction_VTR, Score ANOVA: 1227.526506468632\n",
      "Columna: Risk_9247, Score ANOVA: 1202.9913554487027\n",
      "Columna: Risk_7095, Score ANOVA: 1188.8404205130118\n",
      "Columna: Infraction_KEJT, Score ANOVA: 1142.579039623802\n",
      "Columna: Expenditure_YTR, Score ANOVA: 1111.9996867623413\n",
      "Columna: Base_23737, Score ANOVA: 1088.6703231029933\n",
      "Columna: Infraction_IMIM, Score ANOVA: 958.9174915729785\n",
      "Columna: Base_5441, Score ANOVA: 852.2748844758405\n",
      "Columna: Base_14808, Score ANOVA: 703.0570957115933\n",
      "Columna: Risk_4247, Score ANOVA: 647.4010346774364\n",
      "Columna: Infraction_QVSL, Score ANOVA: 626.5911543622868\n",
      "Columna: Expenditure_HPM, Score ANOVA: 456.67846521501366\n",
      "Columna: Base_1165, Score ANOVA: 258.7934302287576\n",
      "Columna: Infraction_WMAQ, Score ANOVA: 257.80939185973284\n",
      "Columna: Infraction_ZRH, Score ANOVA: 247.45956820393857\n",
      "Columna: Expenditure_XDD, Score ANOVA: 232.9743523088372\n",
      "Columna: Risk_5270, Score ANOVA: 228.52912870884816\n",
      "Columna: Infraction_JYZB, Score ANOVA: 184.15424408585406\n",
      "Columna: Infraction_LTIS, Score ANOVA: 146.48966571821626\n",
      "Columna: Base_36516, Score ANOVA: 135.41204738441706\n",
      "Columna: Infraction_PTY, Score ANOVA: 114.91065950710917\n",
      "Columna: Risk_6197, Score ANOVA: 87.59062429316714\n",
      "Columna: Base_9516, Score ANOVA: 57.50423976577881\n",
      "Columna: Expenditure_AHF_year, Score ANOVA: 46.20530577069537\n",
      "Columna: ID, Score ANOVA: 45.580688578431456\n",
      "Columna: Expenditure_GCAO, Score ANOVA: 29.15500331294239\n",
      "Columna: Expenditure_HKXV, Score ANOVA: 22.093339615067016\n",
      "Columna: Infraction_IBJ, Score ANOVA: 12.176870833659097\n",
      "Columna: Base_0580, Score ANOVA: 8.904020812167017\n",
      "Columna: Expenditure_IDZ, Score ANOVA: 7.145865244158108\n",
      "Columna: Expenditure_AHF_month, Score ANOVA: 4.368294446968924\n",
      "Columna: Expenditure_AHF_day, Score ANOVA: 3.977515395235674\n",
      "Columna: Base_7331, Score ANOVA: 2.853618682994077\n",
      "Columna: Risk_3506, Score ANOVA: 0.019368352326605696\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_merged_part_{i}']\n",
    "    \n",
    "    X = data_frame.drop(columns=['label']).copy()  \n",
    "    y = data_frame['label']\n",
    "\n",
    "    # Calcula el score ANOVA\n",
    "    selector_anova = SelectKBest(score_func=f_classif, k='all')\n",
    "    selector_anova.fit(X, y)\n",
    "    \n",
    "    # Obtiene los scores y los ordena de mayor a menor\n",
    "    scores_anova = dict(zip(X.columns, selector_anova.scores_))\n",
    "    scores_anova_sorted = sorted(scores_anova.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    \n",
    "    print(f'Partición {i}:')\n",
    "    for column, score in scores_anova_sorted:\n",
    "        print(f'Columna: {column}, Score ANOVA: {score}')\n",
    "    print('\\n')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Haz media y mediana de scores_anova_sorted y en el código de thershold + anova ajusta el umbral de anova para borrar las columnas con muy baja varianza y qu afecten poco a la clasificación\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m \u001b[43mscores_anova_sorted\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#Haz media y mediana de scores_anova_sorted y en el código de thershold + anova ajusta el umbral de anova para borrar las columnas con muy baja varianza y qu afecten poco a la clasificación\n",
    "scores_anova_sorted[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas a eliminar por baja varianza y bajo score ANOVA: set()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "import pandas as pd\n",
    "\n",
    "# Diccionario para almacenar las columnas a eliminar por baja varianza y bajo score ANOVA\n",
    "columnas_finales_eliminadas = set()\n",
    "\n",
    "# Recorre cada partición\n",
    "for i in range(1, 8):\n",
    "    # Carga el dataframe y los labels\n",
    "    data_frame = globals()[f'df_merged_part_{i}']\n",
    "    \n",
    "    X = data_frame.drop(columns=['label']).copy()\n",
    "    y = data_frame['label']\n",
    "    \n",
    "    \n",
    "    # Filtra columnas de baja varianza\n",
    "    selector_varianza = VarianceThreshold(threshold=0.01)\n",
    "    selector_varianza.fit(X)\n",
    "    columnas_baja_varianza = X.columns[~selector_varianza.get_support()].tolist()\n",
    "    \n",
    "    # Calcula el score ANOVA\n",
    "    selector_anova = SelectKBest(score_func=f_classif, k='all')\n",
    "    selector_anova.fit(X, y)\n",
    "    scores_anova = dict(zip(X.columns, selector_anova.scores_))\n",
    "    \n",
    "    # Filtra las columnas con baja varianza y bajo score ANOVA\n",
    "    columnas_a_eliminar = [col for col in columnas_baja_varianza if scores_anova[col] < 1]  # Ajusta el umbral del score ANOVA\n",
    "    \n",
    "    # Actualiza el conjunto de columnas a eliminar por baja varianza y bajo score ANOVA\n",
    "    if i == 1:\n",
    "        columnas_finales_eliminadas = set(columnas_a_eliminar)\n",
    "    else:\n",
    "        columnas_finales_eliminadas = columnas_finales_eliminadas.intersection(columnas_a_eliminar)\n",
    "\n",
    "print(f'Columnas a eliminar por baja varianza y bajo score ANOVA: {columnas_finales_eliminadas}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas con más del 80% de valores 0 en df_data_part_1: Index(['Infraction_ZRH'], dtype='object')\n",
      "Columnas con más del 80% de valores 0 en df_data_part_2: Index(['Infraction_ZRH'], dtype='object')\n",
      "Columnas con más del 80% de valores 0 en df_data_part_3: Index(['Infraction_ZRH'], dtype='object')\n",
      "Columnas con más del 80% de valores 0 en df_data_part_4: Index(['Infraction_ZRH'], dtype='object')\n",
      "Columnas con más del 80% de valores 0 en df_data_part_5: Index(['Infraction_ZRH'], dtype='object')\n",
      "Columnas con más del 80% de valores 0 en df_data_part_6: Index(['Infraction_ZRH'], dtype='object')\n",
      "Columnas con más del 80% de valores 0 en df_data_part_7: Index(['Infraction_ZRH'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Quiero saber si existen columnas con casi todos los valores a 0 (el 95$ o más)\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    almost_zeros = data_frame.columns[(data_frame == 0).mean() > 0.95]\n",
    "    print(f'Columnas con más del 95% de valores 0 en df_data_part_{i}: {almost_zeros}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infraction_ZRH\n",
      "0.000000    303518\n",
      "0.001001      9335\n",
      "1.000000       304\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_data_part_{i}']\n",
    "    count_unique = data_frame['Infraction_ZRH'].value_counts()\n",
    "    if i == 1:\n",
    "        unique_values = set(count_unique.index)\n",
    "    else:\n",
    "        unique_values = unique_values.intersection(set(count_unique.index))\n",
    "print(count_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código Halving Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromo sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Lista para guardar los mejores valores de k y las puntuaciones\n",
    "best_k_values = []\n",
    "best_scores = []\n",
    "\n",
    "# Definir el rango de valores de k\n",
    "param_grid = {\n",
    "    'selectkbest__k': np.arange(1, len(df_data_part_1.columns) + 1, step=5)  # Ajusta el step si el rango es amplio\n",
    "}\n",
    "\n",
    "# Bucle para realizar HalvingRandomSearchCV en cada partición\n",
    "\n",
    "# Cargar y combinar datos y etiquetas\n",
    "data_frame = df_data_part_1\n",
    "data_frame_merged = pd.merge(data_frame, df_labels, on='ID', how='inner')\n",
    "\n",
    "# Dividir en X e y\n",
    "X = data_frame.drop(columns=['ID'])\n",
    "y = data_frame_merged['label']\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('selectkbest', SelectKBest(score_func=f_classif)),\n",
    "    ('classifier', RandomForestClassifier(random_state=0))\n",
    "])\n",
    "\n",
    "# Configurar y ejecutar HalvingRandomSearchCV\n",
    "halving_search = HalvingRandomSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=3, \n",
    "    factor=2, \n",
    "    scoring='accuracy',\n",
    "    random_state=0\n",
    ")\n",
    "halving_search.fit(X, y)\n",
    "\n",
    "# Guardar el mejor k y la precisión de esta partición\n",
    "best_k_values.append(halving_search.best_params_['selectkbest__k'])\n",
    "best_scores.append(halving_search.best_score_)\n",
    "\n",
    "# Mostrar resultados de cada partición\n",
    "print(f\"Mejor valor de k: {halving_search.best_params_['selectkbest__k']}\")\n",
    "print(f\" Mejor puntuación de precisión: {halving_search.best_score_}\\n\")\n",
    "\n",
    "# # Calcular la media de los mejores valores de k y las puntuaciones\n",
    "# average_k = int(np.mean(best_k_values))\n",
    "# average_score = np.mean(best_scores)\n",
    "\n",
    "# print(f\"Valor promedio de k en todas las particiones: {average_k}\")\n",
    "# print(f\"Puntuación promedio de precisión en todas las particiones: {average_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Código OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Define la función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Sugerir un valor de k entre 1 y el número de características\n",
    "    k = trial.suggest_int('k', 1, df.shape[1] - 1)  # df.shape[1] - 1 si 'label' está en el DataFrame\n",
    "    \n",
    "    # Preparar datos\n",
    "    X = df.drop(columns=['label'])  # Asegúrate de que 'label' sea la columna de tu variable objetivo\n",
    "    y = df['label']\n",
    "    \n",
    "    # Selección de características con SelectKBest\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Entrenamos un modelo usando las características seleccionadas\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "    scores = cross_val_score(model, X_selected, y, cv=3, scoring='accuracy')  # Ajusta cv según tu necesidad\n",
    "    \n",
    "    # Devolvemos la precisión media para optimizar\n",
    "    return scores.mean()\n",
    "\n",
    "# Crear un estudio de Optuna y optimizar\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Ajusta n_trials según tu tiempo y recursos\n",
    "\n",
    "# Ver el mejor valor de k encontrado\n",
    "print(f\"El mejor valor de k encontrado es: {study.best_params['k']}\")\n",
    "print(f\"Precisión con este k: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inbalanced data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
