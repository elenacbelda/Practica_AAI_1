{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    file_name = f'../data/dataFrame_final/df_final_part_1_{i}.csv'\n",
    "    globals()[f'df_part_{i}'] = pd.read_csv(file_name, encoding='ISO-8859-1')\n",
    "    print(f'Archivo {file_name} cargado en df_part_{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesaria normalización para Redes neuronales y recomendada para Regresión Logística, SVM, Regresión Lineal y Polinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.12 install dask dask-ml joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "\n",
    "# Función para evaluar y guardar resultados de un modelo\n",
    "def evaluate_model( X_test, y_test, model, model_name):\n",
    "   \n",
    "    # Realizar predicciones\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, predictions, average='binary')\n",
    "    auc = metrics.roc_auc_score(y_test, predictions)\n",
    "    \n",
    "    # Guardar el modelo\n",
    "    joblib.dump(model, f\"{model_name}.joblib\")\n",
    "    \n",
    "    # Guardar los resultados en un diccionario\n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': fscore,\n",
    "        'auc': auc\n",
    "    }\n",
    "    \n",
    "    print(f\"Resultados para {model_name}: {results}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función para graficar la comparación de modelos\n",
    "def plot_model_comparison(results_dict):\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc']\n",
    "    fig, ax = plt.subplots(1, len(metrics), figsize=(18, 5), sharey=True)\n",
    "    \n",
    "    # Graficar cada métrica en una subfigura\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax[i].bar(results_dict.keys(), [results[metric] for results in results_dict.values()])\n",
    "        ax[i].set_title(metric.capitalize())\n",
    "        ax[i].set_ylim([0, 1])\n",
    "        ax[i].set_xticklabels(results_dict.keys(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "\n",
    "# Definir el modelo\n",
    "model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    # Cargar el dataframe de la parte correspondiente\n",
    "    data_frame = globals()[f'df_part_{i}']\n",
    "    X_batch = data_frame.drop(columns=['label']).values\n",
    "    y_batch = data_frame['label'].values\n",
    "    \n",
    "    # Entrenamiento incremental\n",
    "    model.partial_fit(X_batch, y_batch)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "dump(model, 'linear_regression_model.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Polinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Creamos el pipeline de regresión polinomial\n",
    "polynomial_model = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=3)),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Evaluamos y guardamos el resultado\n",
    "results_dict['PolynomialRegression'] = evaluate_model(X_train, X_test, y_train, y_test, polynomial_model, 'PolynomialRegression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='saga', max_iter=1000)\n",
    "\n",
    "for i in range(1, 8):\n",
    "    data_frame = globals()[f'df_part_{i}']\n",
    "    X_train = data_frame.drop(columns=['target_column']).values\n",
    "    y_train = data_frame['target_column'].values\n",
    "\n",
    "    # Realiza el entrenamiento incremental\n",
    "    model.partial_fit(X_train, y_train, classes=np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Modelo de Regresión Logística\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Evaluamos y guardamos el resultado\n",
    "results_dict['LogisticRegression'] = evaluate_model(X_train, X_test, y_train, y_test, logistic_model, 'LogisticRegression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Modelo de Árbol de Decisión\n",
    "tree_model = DecisionTreeClassifier()\n",
    "\n",
    "# Evaluamos y guardamos el resultado\n",
    "results_dict['DecisionTree'] = evaluate_model(X_train, X_test, y_train, y_test, tree_model, 'DecisionTree')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basado en instancias : KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Modelo de K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Evaluamos y guardamos el resultado\n",
    "results_dict['KNeighbors'] = evaluate_model(X_train, X_test, y_train, y_test, knn_model, 'KNeighbors')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Máquinas de soporte vectorial : SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Modelo de SVM\n",
    "svm_model = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# Evaluamos y guardamos el resultado\n",
    "results_dict['SVM'] = evaluate_model(X_train, X_test, y_train, y_test, svm_model, 'SVM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes neuronales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Modelo de Red Neuronal\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42)\n",
    "\n",
    "# Evaluamos y guardamos el resultado\n",
    "results_dict['NeuralNetwork'] = evaluate_model(X_train, X_test, y_train, y_test, nn_model, 'NeuralNetwork')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la comparación de los modelos\n",
    "plot_model_comparison(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevos resultados"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
